{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7250c14",
   "metadata": {},
   "source": [
    "### Mental-RoBERTa\n",
    "[Training - Mental-RoBERTa + Original labels](#1)  \n",
    "[Training - Mental-RoBERTa + Original labels + Personality (Benchmark)](#2)            \n",
    "[Training - Mental-RoBERTa + Relabeled data](#3)       \n",
    "[Training - Mental-RoBERTa + Relabeled + Personality](#4)      \n",
    "\n",
    "<u>[Testing results](#5)</u>  \n",
    "[Mental-RoBERTa + Original labels](#6)  \n",
    "[Mental-RoBERTa + Original labels + Personality (Benchmark)](#7)            \n",
    "[Mental-RoBERTa + Relabeled data](#8)       \n",
    "[Mental-RoBERTa + Relabeled + Personality](#9)     \n",
    "[Mental-RoBERTa + Relabeled data + NLI](#10)       \n",
    "[Mental-RoBERTa + Relabeled + Personality + NLI](#11)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd83553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set the seed value\n",
    "seed_val = 42\n",
    "\n",
    "# Python random\n",
    "random.seed(seed_val)\n",
    "\n",
    "# NumPy random\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# PyTorch random\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bba445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, RobertaModel, RobertaConfig, RobertaPreTrainedModel, AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2037be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>text</th>\n",
       "      <th>ori_class</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>true_class</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79033</td>\n",
       "      <td>Here are some jokes that don't have a punchlin...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>Here are some jokes that don't have a punchlin...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0.862079</td>\n",
       "      <td>0.632528</td>\n",
       "      <td>0.299561</td>\n",
       "      <td>0.650520</td>\n",
       "      <td>0.004304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>257115</td>\n",
       "      <td>I'll begin to blog on here before I end it on ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>I'll begin to blog on here before I end it on ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>0.561344</td>\n",
       "      <td>0.527004</td>\n",
       "      <td>0.222416</td>\n",
       "      <td>0.461801</td>\n",
       "      <td>0.022128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102858</td>\n",
       "      <td>Just saw two friends vape, Do I snitch? So I l...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>Just saw two friends vape, Do I snitch? So I l...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0.726340</td>\n",
       "      <td>0.389685</td>\n",
       "      <td>0.347877</td>\n",
       "      <td>0.707561</td>\n",
       "      <td>0.022913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188810</td>\n",
       "      <td>Hey lads! Can I get some help from y'all? So.....</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>Hey lads! Can I get some help from y'all? So.....</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0.753932</td>\n",
       "      <td>0.489636</td>\n",
       "      <td>0.230587</td>\n",
       "      <td>0.776817</td>\n",
       "      <td>0.031480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88124</td>\n",
       "      <td>Why do parents always bring up their “stories”...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>Why do parents always bring up their \"stories\"...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0.802898</td>\n",
       "      <td>0.768912</td>\n",
       "      <td>0.275205</td>\n",
       "      <td>0.437977</td>\n",
       "      <td>0.032501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>272846</td>\n",
       "      <td>ContemplationI have everything I need to do It...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>Contemplation. I have everything I need to do ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>0.747140</td>\n",
       "      <td>0.331684</td>\n",
       "      <td>0.412662</td>\n",
       "      <td>0.536295</td>\n",
       "      <td>0.939585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>49620</td>\n",
       "      <td>I don't want to get better, I want to get wors...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>I don't want to get better, I want to get wors...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>0.437285</td>\n",
       "      <td>0.340145</td>\n",
       "      <td>0.125675</td>\n",
       "      <td>0.653872</td>\n",
       "      <td>0.946523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>291094</td>\n",
       "      <td>My only friend died and I want to go with him....</td>\n",
       "      <td>suicide</td>\n",
       "      <td>My only friend died and I want to go with him....</td>\n",
       "      <td>suicide</td>\n",
       "      <td>0.395193</td>\n",
       "      <td>0.474021</td>\n",
       "      <td>0.074487</td>\n",
       "      <td>0.620530</td>\n",
       "      <td>0.958698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>138491</td>\n",
       "      <td>I fantasize about dying all the timeI think th...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>I fantasize about dying all the time. I think ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>0.604205</td>\n",
       "      <td>0.529648</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.512029</td>\n",
       "      <td>0.966551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>193733</td>\n",
       "      <td>Help me.I just want someone there for me. I'm ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>Help me.I just want someone there for me. I'm ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>0.761854</td>\n",
       "      <td>0.346296</td>\n",
       "      <td>0.210556</td>\n",
       "      <td>0.428369</td>\n",
       "      <td>1.020516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Column1                                               text    ori_class  \\\n",
       "0       79033  Here are some jokes that don't have a punchlin...  non-suicide   \n",
       "1      257115  I'll begin to blog on here before I end it on ...      suicide   \n",
       "2      102858  Just saw two friends vape, Do I snitch? So I l...  non-suicide   \n",
       "3      188810  Hey lads! Can I get some help from y'all? So.....  non-suicide   \n",
       "4       88124  Why do parents always bring up their “stories”...  non-suicide   \n",
       "...       ...                                                ...          ...   \n",
       "1995   272846  ContemplationI have everything I need to do It...      suicide   \n",
       "1996    49620  I don't want to get better, I want to get wors...      suicide   \n",
       "1997   291094  My only friend died and I want to go with him....      suicide   \n",
       "1998   138491  I fantasize about dying all the timeI think th...      suicide   \n",
       "1999   193733  Help me.I just want someone there for me. I'm ...      suicide   \n",
       "\n",
       "                                           cleaned_text   true_class  \\\n",
       "0     Here are some jokes that don't have a punchlin...  non-suicide   \n",
       "1     I'll begin to blog on here before I end it on ...      suicide   \n",
       "2     Just saw two friends vape, Do I snitch? So I l...  non-suicide   \n",
       "3     Hey lads! Can I get some help from y'all? So.....  non-suicide   \n",
       "4     Why do parents always bring up their \"stories\"...  non-suicide   \n",
       "...                                                 ...          ...   \n",
       "1995  Contemplation. I have everything I need to do ...      suicide   \n",
       "1996  I don't want to get better, I want to get wors...      suicide   \n",
       "1997  My only friend died and I want to go with him....      suicide   \n",
       "1998  I fantasize about dying all the time. I think ...      suicide   \n",
       "1999  Help me.I just want someone there for me. I'm ...      suicide   \n",
       "\n",
       "      openness  conscientiousness  extraversion  agreeableness  neuroticism  \n",
       "0     0.862079           0.632528      0.299561       0.650520     0.004304  \n",
       "1     0.561344           0.527004      0.222416       0.461801     0.022128  \n",
       "2     0.726340           0.389685      0.347877       0.707561     0.022913  \n",
       "3     0.753932           0.489636      0.230587       0.776817     0.031480  \n",
       "4     0.802898           0.768912      0.275205       0.437977     0.032501  \n",
       "...        ...                ...           ...            ...          ...  \n",
       "1995  0.747140           0.331684      0.412662       0.536295     0.939585  \n",
       "1996  0.437285           0.340145      0.125675       0.653872     0.946523  \n",
       "1997  0.395193           0.474021      0.074487       0.620530     0.958698  \n",
       "1998  0.604205           0.529648      0.226070       0.512029     0.966551  \n",
       "1999  0.761854           0.346296      0.210556       0.428369     1.020516  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/relabeled_2000_samples_2.csv', encoding='utf-8-sig')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57325315",
   "metadata": {},
   "source": [
    "#### 1\n",
    "- Original labels (2000 samples)\n",
    "- textual features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5595fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Documents\\Master_Project\\Suicide-Ideation-Detection-in-Social-Media-Using-Personality-Traits-main\\venv\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "  Train Loss: 0.4568\n",
      "  Val Loss:   0.2571\n",
      "  Val Acc:    0.9050\n",
      "------------------------------\n",
      "Epoch 2\n",
      "  Train Loss: 0.2369\n",
      "  Val Loss:   0.3760\n",
      "  Val Acc:    0.8625\n",
      "------------------------------\n",
      "Epoch 3\n",
      "  Train Loss: 0.1900\n",
      "  Val Loss:   0.2550\n",
      "  Val Acc:    0.9050\n",
      "------------------------------\n",
      "Epoch 4\n",
      "  Train Loss: 0.1321\n",
      "  Val Loss:   0.3687\n",
      "  Val Acc:    0.8975\n",
      "------------------------------\n",
      "Mental-RoBERTa Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7865    0.8805       192\n",
      "           1     0.8353    1.0000    0.9103       208\n",
      "\n",
      "    accuracy                         0.8975       400\n",
      "   macro avg     0.9177    0.8932    0.8954       400\n",
      "weighted avg     0.9144    0.8975    0.8960       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "texts = data['cleaned_text'].tolist()\n",
    "labels = data['ori_class'].map({'suicide': 1, 'non-suicide': 0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mental/mental-roberta-base\",\n",
    "    token=True  \n",
    ")\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    texts.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded_data['input_ids']\n",
    "attention_masks = encoded_data['attention_mask']\n",
    "labels = torch.tensor(labels.values, dtype=torch.long)  # ensure integer labels\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"mental/mental-roberta-base\",\n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.3,      \n",
    "    attention_probs_dropout_prob=0.3  \n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('mental/mental-roberta-base',config=config)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# use cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(4):\n",
    "\n",
    "    # train loop\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    val_probs = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # calculate probabilities for roc_auc_score\n",
    "        probs = torch.nn.functional.softmax(torch.from_numpy(logits), dim=1).numpy()\n",
    "        val_probs.extend(probs)\n",
    "\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        val_labels.extend(label_ids)\n",
    "        val_preds.extend(predictions)\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"  Val Acc:    {val_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print('Mental-RoBERTa Results:')\n",
    "print(classification_report(val_labels, val_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c87653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-suicide', 'Suicide'], yticklabels=['Non-suicide', 'Suicide'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix (Mental-RoBERTa) - Original labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897729d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\2278315184.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\2278315184.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 41\n",
      "                                                 text  true_label  pred_label  \\\n",
      "5   A rant, if you will. This is almost everything...           0           1   \n",
      "10  I'm insanely paranoid rn someone hear me out p...           0           1   \n",
      "11  Why do people make me feel disregarded and uni...           0           1   \n",
      "30  WHY ME Every time I send a message. Always in ...           0           1   \n",
      "34  I think I should be back in the mental hospita...           0           1   \n",
      "41  My life right now I literally just woke up fro...           0           1   \n",
      "42  I got offered to go to Harvard. I'm stressed a...           0           1   \n",
      "53  I really want to see my friend again. I met on...           0           1   \n",
      "55  I miss affection. To the few people who see th...           0           1   \n",
      "56  I'm happy. A few years ago, I was extremely de...           0           1   \n",
      "\n",
      "   true_label_name pred_label_name  \n",
      "5      non-suicide         suicide  \n",
      "10     non-suicide         suicide  \n",
      "11     non-suicide         suicide  \n",
      "30     non-suicide         suicide  \n",
      "34     non-suicide         suicide  \n",
      "41     non-suicide         suicide  \n",
      "42     non-suicide         suicide  \n",
      "53     non-suicide         suicide  \n",
      "55     non-suicide         suicide  \n",
      "56     non-suicide         suicide  \n",
      "Model state dict and tokenizer saved to ../saved_models/mental_roberta_raw\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "output_dir = \"../saved_models/mental_roberta_raw\"\n",
    "\n",
    "#save misclassified samples\n",
    "val_indices = val_dataset.indices if hasattr(val_dataset, 'indices') else np.arange(len(val_dataset))\n",
    "\n",
    "val_texts = [texts[i] for i in val_indices]\n",
    "val_true_labels = [labels[i].item() for i in val_indices]  \n",
    "val_pred_labels = val_preds  \n",
    "\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'text': val_texts,\n",
    "    'true_label': val_true_labels,\n",
    "    'pred_label': val_pred_labels\n",
    "})\n",
    "\n",
    "# Filter misclassified samples\n",
    "misclassified_df = val_df[val_df['true_label'] != val_df['pred_label']]\n",
    "\n",
    "# Optionally, map label numbers back to class names\n",
    "label_map = {0: 'non-suicide', 1: 'suicide'}\n",
    "misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
    "misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n",
    "\n",
    "print(f\"Number of misclassified samples: {len(misclassified_df)}\")\n",
    "print(misclassified_df.head(10))  # view first 10 misclassified samples\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "misclassified_df.to_csv(output_dir + '/misclassified_samples.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Model state dict and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db7289e",
   "metadata": {},
   "source": [
    "### 2 \n",
    "- Original labels (2000 samples)\n",
    "- Textual features + Personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6c3113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RoBertaWithPersonality were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.bert.embeddings.LayerNorm.bias', 'roberta.bert.embeddings.LayerNorm.weight', 'roberta.bert.embeddings.position_embeddings.weight', 'roberta.bert.embeddings.token_type_embeddings.weight', 'roberta.bert.embeddings.word_embeddings.weight', 'roberta.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.0.attention.output.dense.bias', 'roberta.bert.encoder.layer.0.attention.output.dense.weight', 'roberta.bert.encoder.layer.0.attention.self.key.bias', 'roberta.bert.encoder.layer.0.attention.self.key.weight', 'roberta.bert.encoder.layer.0.attention.self.query.bias', 'roberta.bert.encoder.layer.0.attention.self.query.weight', 'roberta.bert.encoder.layer.0.attention.self.value.bias', 'roberta.bert.encoder.layer.0.attention.self.value.weight', 'roberta.bert.encoder.layer.0.intermediate.dense.bias', 'roberta.bert.encoder.layer.0.intermediate.dense.weight', 'roberta.bert.encoder.layer.0.output.LayerNorm.bias', 'roberta.bert.encoder.layer.0.output.LayerNorm.weight', 'roberta.bert.encoder.layer.0.output.dense.bias', 'roberta.bert.encoder.layer.0.output.dense.weight', 'roberta.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.1.attention.output.dense.bias', 'roberta.bert.encoder.layer.1.attention.output.dense.weight', 'roberta.bert.encoder.layer.1.attention.self.key.bias', 'roberta.bert.encoder.layer.1.attention.self.key.weight', 'roberta.bert.encoder.layer.1.attention.self.query.bias', 'roberta.bert.encoder.layer.1.attention.self.query.weight', 'roberta.bert.encoder.layer.1.attention.self.value.bias', 'roberta.bert.encoder.layer.1.attention.self.value.weight', 'roberta.bert.encoder.layer.1.intermediate.dense.bias', 'roberta.bert.encoder.layer.1.intermediate.dense.weight', 'roberta.bert.encoder.layer.1.output.LayerNorm.bias', 'roberta.bert.encoder.layer.1.output.LayerNorm.weight', 'roberta.bert.encoder.layer.1.output.dense.bias', 'roberta.bert.encoder.layer.1.output.dense.weight', 'roberta.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.10.attention.output.dense.bias', 'roberta.bert.encoder.layer.10.attention.output.dense.weight', 'roberta.bert.encoder.layer.10.attention.self.key.bias', 'roberta.bert.encoder.layer.10.attention.self.key.weight', 'roberta.bert.encoder.layer.10.attention.self.query.bias', 'roberta.bert.encoder.layer.10.attention.self.query.weight', 'roberta.bert.encoder.layer.10.attention.self.value.bias', 'roberta.bert.encoder.layer.10.attention.self.value.weight', 'roberta.bert.encoder.layer.10.intermediate.dense.bias', 'roberta.bert.encoder.layer.10.intermediate.dense.weight', 'roberta.bert.encoder.layer.10.output.LayerNorm.bias', 'roberta.bert.encoder.layer.10.output.LayerNorm.weight', 'roberta.bert.encoder.layer.10.output.dense.bias', 'roberta.bert.encoder.layer.10.output.dense.weight', 'roberta.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.11.attention.output.dense.bias', 'roberta.bert.encoder.layer.11.attention.output.dense.weight', 'roberta.bert.encoder.layer.11.attention.self.key.bias', 'roberta.bert.encoder.layer.11.attention.self.key.weight', 'roberta.bert.encoder.layer.11.attention.self.query.bias', 'roberta.bert.encoder.layer.11.attention.self.query.weight', 'roberta.bert.encoder.layer.11.attention.self.value.bias', 'roberta.bert.encoder.layer.11.attention.self.value.weight', 'roberta.bert.encoder.layer.11.intermediate.dense.bias', 'roberta.bert.encoder.layer.11.intermediate.dense.weight', 'roberta.bert.encoder.layer.11.output.LayerNorm.bias', 'roberta.bert.encoder.layer.11.output.LayerNorm.weight', 'roberta.bert.encoder.layer.11.output.dense.bias', 'roberta.bert.encoder.layer.11.output.dense.weight', 'roberta.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.2.attention.output.dense.bias', 'roberta.bert.encoder.layer.2.attention.output.dense.weight', 'roberta.bert.encoder.layer.2.attention.self.key.bias', 'roberta.bert.encoder.layer.2.attention.self.key.weight', 'roberta.bert.encoder.layer.2.attention.self.query.bias', 'roberta.bert.encoder.layer.2.attention.self.query.weight', 'roberta.bert.encoder.layer.2.attention.self.value.bias', 'roberta.bert.encoder.layer.2.attention.self.value.weight', 'roberta.bert.encoder.layer.2.intermediate.dense.bias', 'roberta.bert.encoder.layer.2.intermediate.dense.weight', 'roberta.bert.encoder.layer.2.output.LayerNorm.bias', 'roberta.bert.encoder.layer.2.output.LayerNorm.weight', 'roberta.bert.encoder.layer.2.output.dense.bias', 'roberta.bert.encoder.layer.2.output.dense.weight', 'roberta.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.3.attention.output.dense.bias', 'roberta.bert.encoder.layer.3.attention.output.dense.weight', 'roberta.bert.encoder.layer.3.attention.self.key.bias', 'roberta.bert.encoder.layer.3.attention.self.key.weight', 'roberta.bert.encoder.layer.3.attention.self.query.bias', 'roberta.bert.encoder.layer.3.attention.self.query.weight', 'roberta.bert.encoder.layer.3.attention.self.value.bias', 'roberta.bert.encoder.layer.3.attention.self.value.weight', 'roberta.bert.encoder.layer.3.intermediate.dense.bias', 'roberta.bert.encoder.layer.3.intermediate.dense.weight', 'roberta.bert.encoder.layer.3.output.LayerNorm.bias', 'roberta.bert.encoder.layer.3.output.LayerNorm.weight', 'roberta.bert.encoder.layer.3.output.dense.bias', 'roberta.bert.encoder.layer.3.output.dense.weight', 'roberta.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.4.attention.output.dense.bias', 'roberta.bert.encoder.layer.4.attention.output.dense.weight', 'roberta.bert.encoder.layer.4.attention.self.key.bias', 'roberta.bert.encoder.layer.4.attention.self.key.weight', 'roberta.bert.encoder.layer.4.attention.self.query.bias', 'roberta.bert.encoder.layer.4.attention.self.query.weight', 'roberta.bert.encoder.layer.4.attention.self.value.bias', 'roberta.bert.encoder.layer.4.attention.self.value.weight', 'roberta.bert.encoder.layer.4.intermediate.dense.bias', 'roberta.bert.encoder.layer.4.intermediate.dense.weight', 'roberta.bert.encoder.layer.4.output.LayerNorm.bias', 'roberta.bert.encoder.layer.4.output.LayerNorm.weight', 'roberta.bert.encoder.layer.4.output.dense.bias', 'roberta.bert.encoder.layer.4.output.dense.weight', 'roberta.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.5.attention.output.dense.bias', 'roberta.bert.encoder.layer.5.attention.output.dense.weight', 'roberta.bert.encoder.layer.5.attention.self.key.bias', 'roberta.bert.encoder.layer.5.attention.self.key.weight', 'roberta.bert.encoder.layer.5.attention.self.query.bias', 'roberta.bert.encoder.layer.5.attention.self.query.weight', 'roberta.bert.encoder.layer.5.attention.self.value.bias', 'roberta.bert.encoder.layer.5.attention.self.value.weight', 'roberta.bert.encoder.layer.5.intermediate.dense.bias', 'roberta.bert.encoder.layer.5.intermediate.dense.weight', 'roberta.bert.encoder.layer.5.output.LayerNorm.bias', 'roberta.bert.encoder.layer.5.output.LayerNorm.weight', 'roberta.bert.encoder.layer.5.output.dense.bias', 'roberta.bert.encoder.layer.5.output.dense.weight', 'roberta.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.6.attention.output.dense.bias', 'roberta.bert.encoder.layer.6.attention.output.dense.weight', 'roberta.bert.encoder.layer.6.attention.self.key.bias', 'roberta.bert.encoder.layer.6.attention.self.key.weight', 'roberta.bert.encoder.layer.6.attention.self.query.bias', 'roberta.bert.encoder.layer.6.attention.self.query.weight', 'roberta.bert.encoder.layer.6.attention.self.value.bias', 'roberta.bert.encoder.layer.6.attention.self.value.weight', 'roberta.bert.encoder.layer.6.intermediate.dense.bias', 'roberta.bert.encoder.layer.6.intermediate.dense.weight', 'roberta.bert.encoder.layer.6.output.LayerNorm.bias', 'roberta.bert.encoder.layer.6.output.LayerNorm.weight', 'roberta.bert.encoder.layer.6.output.dense.bias', 'roberta.bert.encoder.layer.6.output.dense.weight', 'roberta.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.7.attention.output.dense.bias', 'roberta.bert.encoder.layer.7.attention.output.dense.weight', 'roberta.bert.encoder.layer.7.attention.self.key.bias', 'roberta.bert.encoder.layer.7.attention.self.key.weight', 'roberta.bert.encoder.layer.7.attention.self.query.bias', 'roberta.bert.encoder.layer.7.attention.self.query.weight', 'roberta.bert.encoder.layer.7.attention.self.value.bias', 'roberta.bert.encoder.layer.7.attention.self.value.weight', 'roberta.bert.encoder.layer.7.intermediate.dense.bias', 'roberta.bert.encoder.layer.7.intermediate.dense.weight', 'roberta.bert.encoder.layer.7.output.LayerNorm.bias', 'roberta.bert.encoder.layer.7.output.LayerNorm.weight', 'roberta.bert.encoder.layer.7.output.dense.bias', 'roberta.bert.encoder.layer.7.output.dense.weight', 'roberta.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.8.attention.output.dense.bias', 'roberta.bert.encoder.layer.8.attention.output.dense.weight', 'roberta.bert.encoder.layer.8.attention.self.key.bias', 'roberta.bert.encoder.layer.8.attention.self.key.weight', 'roberta.bert.encoder.layer.8.attention.self.query.bias', 'roberta.bert.encoder.layer.8.attention.self.query.weight', 'roberta.bert.encoder.layer.8.attention.self.value.bias', 'roberta.bert.encoder.layer.8.attention.self.value.weight', 'roberta.bert.encoder.layer.8.intermediate.dense.bias', 'roberta.bert.encoder.layer.8.intermediate.dense.weight', 'roberta.bert.encoder.layer.8.output.LayerNorm.bias', 'roberta.bert.encoder.layer.8.output.LayerNorm.weight', 'roberta.bert.encoder.layer.8.output.dense.bias', 'roberta.bert.encoder.layer.8.output.dense.weight', 'roberta.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.9.attention.output.dense.bias', 'roberta.bert.encoder.layer.9.attention.output.dense.weight', 'roberta.bert.encoder.layer.9.attention.self.key.bias', 'roberta.bert.encoder.layer.9.attention.self.key.weight', 'roberta.bert.encoder.layer.9.attention.self.query.bias', 'roberta.bert.encoder.layer.9.attention.self.query.weight', 'roberta.bert.encoder.layer.9.attention.self.value.bias', 'roberta.bert.encoder.layer.9.attention.self.value.weight', 'roberta.bert.encoder.layer.9.intermediate.dense.bias', 'roberta.bert.encoder.layer.9.intermediate.dense.weight', 'roberta.bert.encoder.layer.9.output.LayerNorm.bias', 'roberta.bert.encoder.layer.9.output.LayerNorm.weight', 'roberta.bert.encoder.layer.9.output.dense.bias', 'roberta.bert.encoder.layer.9.output.dense.weight', 'roberta.bert.pooler.dense.bias', 'roberta.bert.pooler.dense.weight', 'roberta.classifier.0.bias', 'roberta.classifier.0.weight', 'roberta.classifier.3.bias', 'roberta.classifier.3.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "  Train Loss: 0.5542\n",
      "  Val Loss:   0.3303\n",
      "  Val Acc:    0.8900\n",
      "------------------------------\n",
      "Epoch 2\n",
      "  Train Loss: 0.3006\n",
      "  Val Loss:   0.3437\n",
      "  Val Acc:    0.8900\n",
      "------------------------------\n",
      "Epoch 3\n",
      "  Train Loss: 0.2275\n",
      "  Val Loss:   0.3568\n",
      "  Val Acc:    0.8800\n",
      "------------------------------\n",
      "Epoch 4\n",
      "  Train Loss: 0.2017\n",
      "  Val Loss:   0.2807\n",
      "  Val Acc:    0.9000\n",
      "------------------------------\n",
      "RoBERTa Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9932    0.7903    0.8802       186\n",
      "           1     0.8452    0.9953    0.9142       214\n",
      "\n",
      "    accuracy                         0.9000       400\n",
      "   macro avg     0.9192    0.8928    0.8972       400\n",
      "weighted avg     0.9141    0.9000    0.8984       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "# === Load data including personality features ===\n",
    "texts = data['cleaned_text'].tolist()\n",
    "labels = data['ori_class'].map({'suicide': 1, 'non-suicide': 0})\n",
    "personality_features = data[[\"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "personality_features = torch.tensor(personality_features, dtype=torch.float32)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mental/mental-roberta-base')\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    texts,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded_data['input_ids']\n",
    "attention_masks = encoded_data['attention_mask']\n",
    "labels = torch.tensor(labels.values, dtype=torch.long) \n",
    "\n",
    "# Dataset with text tokens + personality features\n",
    "class RoBertaWithPersonalityDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, personality_feats, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.personality_feats = personality_feats\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.input_ids[idx],\n",
    "                self.attention_masks[idx],\n",
    "                self.personality_feats[idx],\n",
    "                self.labels[idx])\n",
    "    \n",
    "dataset = RoBertaWithPersonalityDataset(input_ids, attention_masks, personality_features, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ===== Custom model combining RoBERTa+ Personality Features =====\n",
    "class RoBertaWithPersonality(RobertaPreTrainedModel):\n",
    "    def __init__(self, config, personality_feat_dim=3, num_labels=2):\n",
    "        super().__init__(config)\n",
    "        self.bert = RobertaModel.from_pretrained(\"mental/mental-roberta-base\", config=config)\n",
    "        bert_hidden_size = config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert_hidden_size + personality_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, personality_feats, labels=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = bert_outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "        combined = torch.cat((cls_output, personality_feats), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ===== Config =====\n",
    "config = AutoConfig.from_pretrained(\n",
    "    'mental/mental-roberta-base',\n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.3,          \n",
    "    attention_probs_dropout_prob=0.3  \n",
    ")\n",
    "\n",
    "model = RoBertaWithPersonality.from_pretrained(\"mental/mental-roberta-base\", config=config)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# ===== Training Loop =====\n",
    "for epoch in range(4):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_personality, b_labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "        logits = model(b_input_ids, attention_mask=b_input_mask, personality_feats=b_personality)\n",
    "\n",
    "        loss = criterion(logits, b_labels)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_labels, val_preds, val_probs = [], [], []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_personality, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, attention_mask=b_input_mask, personality_feats=b_personality)\n",
    "            loss = criterion(logits, b_labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Probabilities for ROC-AUC\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "            val_probs.extend(probs)\n",
    "\n",
    "            predictions = np.argmax(logits.cpu().numpy(), axis=1)\n",
    "            val_labels.extend(label_ids)\n",
    "            val_preds.extend(predictions)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"  Val Acc:    {val_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"RoBERTa Results:\")\n",
    "print(classification_report(val_labels, val_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c9c5b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-suicide', 'Suicide'], yticklabels=['Non-suicide', 'Suicide'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix (Mental-RoBERTa) - Original labels + Personality (Benchmark)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc27a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 40\n",
      "                                                 text  true_label  pred_label  \\\n",
      "0   MEN: Innovate The Stigma Innovative Approach T...           0           1   \n",
      "10  Being lonely kinda sucks I'm only human, and I...           0           1   \n",
      "41  Hi, just dropping something off I needa say so...           0           1   \n",
      "56  Fuck me, guys.... So I'm not trying to toot my...           0           1   \n",
      "63  Don't do what I did Basically I wasted my diam...           0           1   \n",
      "67  You ever look at your life..... And realize th...           0           1   \n",
      "79  i hate my mother im being serious. i dont like...           0           1   \n",
      "81  I dont know how to make good friends. Long sto...           0           1   \n",
      "87  One of our two kittens passed away today. The ...           0           1   \n",
      "88  I'm just going to rant about how perfect my fr...           0           1   \n",
      "\n",
      "   true_label_name pred_label_name  \n",
      "0      non-suicide         suicide  \n",
      "10     non-suicide         suicide  \n",
      "41     non-suicide         suicide  \n",
      "56     non-suicide         suicide  \n",
      "63     non-suicide         suicide  \n",
      "67     non-suicide         suicide  \n",
      "79     non-suicide         suicide  \n",
      "81     non-suicide         suicide  \n",
      "87     non-suicide         suicide  \n",
      "88     non-suicide         suicide  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\2313390417.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\2313390417.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state dict and tokenizer saved to ../saved_models/mental_roberta_raw_personality\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "output_dir = \"../saved_models/mental_roberta_raw_personality\"\n",
    "\n",
    "#save misclassified samples\n",
    "val_indices = val_dataset.indices if hasattr(val_dataset, 'indices') else np.arange(len(val_dataset))\n",
    "\n",
    "val_texts = [texts[i] for i in val_indices]\n",
    "val_true_labels = [labels[i].item() for i in val_indices]  \n",
    "val_pred_labels = val_preds  \n",
    "\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'text': val_texts,\n",
    "    'true_label': val_true_labels,\n",
    "    'pred_label': val_pred_labels\n",
    "})\n",
    "\n",
    "# Filter misclassified samples\n",
    "misclassified_df = val_df[val_df['true_label'] != val_df['pred_label']]\n",
    "\n",
    "# Optionally, map label numbers back to class names\n",
    "label_map = {0: 'non-suicide', 1: 'suicide'}\n",
    "misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
    "misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n",
    "\n",
    "print(f\"Number of misclassified samples: {len(misclassified_df)}\")\n",
    "print(misclassified_df.head(10))  # view first 10 misclassified samples\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "misclassified_df.to_csv(output_dir + '/misclassified_samples.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Model state dict and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd5592",
   "metadata": {},
   "source": [
    "#### 3\n",
    "- relabeled 2000 samples\n",
    "- textual features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "394efb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "  Train Loss: 0.4914\n",
      "  Val Loss:   0.2174\n",
      "  Val Acc:    0.9150\n",
      "------------------------------\n",
      "Epoch 2\n",
      "  Train Loss: 0.2288\n",
      "  Val Loss:   0.1983\n",
      "  Val Acc:    0.9200\n",
      "------------------------------\n",
      "Epoch 3\n",
      "  Train Loss: 0.1715\n",
      "  Val Loss:   0.1820\n",
      "  Val Acc:    0.9375\n",
      "------------------------------\n",
      "Epoch 4\n",
      "  Train Loss: 0.1497\n",
      "  Val Loss:   0.1940\n",
      "  Val Acc:    0.9375\n",
      "------------------------------\n",
      "RoBERTa Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9368    0.9319    0.9344       191\n",
      "           1     0.9381    0.9426    0.9403       209\n",
      "\n",
      "    accuracy                         0.9375       400\n",
      "   macro avg     0.9375    0.9373    0.9374       400\n",
      "weighted avg     0.9375    0.9375    0.9375       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "\n",
    "texts = data['cleaned_text'].tolist()\n",
    "labels = data['true_class'].map({'suicide': 1, 'non-suicide': 0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mental/mental-roberta-base\")\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    texts,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded_data['input_ids']\n",
    "attention_masks = encoded_data['attention_mask']\n",
    "labels = torch.tensor(labels.values, dtype=torch.long)  # ensure integer labels\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"mental/mental-roberta-base\",\n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.3,      \n",
    "    attention_probs_dropout_prob=0.3  \n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"mental/mental-roberta-base\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# use cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(4):\n",
    "\n",
    "    # train loop\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    val_probs = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # calculate probabilities for roc_auc_score\n",
    "        probs = torch.nn.functional.softmax(torch.from_numpy(logits), dim=1).numpy()\n",
    "        val_probs.extend(probs)\n",
    "\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        val_labels.extend(label_ids)\n",
    "        val_preds.extend(predictions)\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"  Val Acc:    {val_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print('RoBERTa Results:')\n",
    "print(classification_report(val_labels, val_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae95356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-suicide', 'Suicide'], yticklabels=['Non-suicide', 'Suicide'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix (Mental-RoBERTa) - relabeled')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "988fada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 25\n",
      "                                                  text  true_label  \\\n",
      "2    Update. A while back I'd posted about some sui...           0   \n",
      "12   Count Down To Death Date: 2I had a dream last ...           1   \n",
      "17   Social anxiety has taken everything.Most of yo...           1   \n",
      "37   I need your help, fellow suicide watch users. ...           0   \n",
      "43   i might do my plan today im sorry. I've been p...           1   \n",
      "54   How can I get over the past?When I was around ...           1   \n",
      "74   I only get good grades to look good in front o...           0   \n",
      "164  You ever look at your life..... And realize th...           0   \n",
      "181  I made a power point.I don't know how you migh...           1   \n",
      "204  Hey.Hey guys... First of all pls don't make fu...           1   \n",
      "\n",
      "     pred_label true_label_name pred_label_name  \n",
      "2             1     non-suicide         suicide  \n",
      "12            0         suicide     non-suicide  \n",
      "17            0         suicide     non-suicide  \n",
      "37            1     non-suicide         suicide  \n",
      "43            0         suicide     non-suicide  \n",
      "54            0         suicide     non-suicide  \n",
      "74            1     non-suicide         suicide  \n",
      "164           1     non-suicide         suicide  \n",
      "181           0         suicide     non-suicide  \n",
      "204           0         suicide     non-suicide  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\408416877.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\408416877.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state dict and tokenizer saved to ../saved_models/mental_roberta_relabeled\n"
     ]
    }
   ],
   "source": [
    "#save misclassified samples\n",
    "val_indices = val_dataset.indices if hasattr(val_dataset, 'indices') else np.arange(len(val_dataset))\n",
    "\n",
    "val_texts = [texts[i] for i in val_indices]\n",
    "val_true_labels = [labels[i].item() for i in val_indices]  \n",
    "val_pred_labels = val_preds  \n",
    "\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'text': val_texts,\n",
    "    'true_label': val_true_labels,\n",
    "    'pred_label': val_pred_labels\n",
    "})\n",
    "\n",
    "# Filter misclassified samples\n",
    "misclassified_df = val_df[val_df['true_label'] != val_df['pred_label']]\n",
    "\n",
    "# Optionally, map label numbers back to class names\n",
    "label_map = {0: 'non-suicide', 1: 'suicide'}\n",
    "misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
    "misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n",
    "\n",
    "print(f\"Number of misclassified samples: {len(misclassified_df)}\")\n",
    "print(misclassified_df.head(10))  \n",
    "\n",
    "# Save the model\n",
    "output_dir = \"../saved_models/mental_roberta_relabeled\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "misclassified_df.to_csv(output_dir + '/misclassified_samples.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Model state dict and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f7a2a",
   "metadata": {},
   "source": [
    "#### 4\n",
    "- relabeled 2000 samples\n",
    "- textual features + personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a530e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RoBertaWithPersonality were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.bert.embeddings.LayerNorm.bias', 'roberta.bert.embeddings.LayerNorm.weight', 'roberta.bert.embeddings.position_embeddings.weight', 'roberta.bert.embeddings.token_type_embeddings.weight', 'roberta.bert.embeddings.word_embeddings.weight', 'roberta.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.0.attention.output.dense.bias', 'roberta.bert.encoder.layer.0.attention.output.dense.weight', 'roberta.bert.encoder.layer.0.attention.self.key.bias', 'roberta.bert.encoder.layer.0.attention.self.key.weight', 'roberta.bert.encoder.layer.0.attention.self.query.bias', 'roberta.bert.encoder.layer.0.attention.self.query.weight', 'roberta.bert.encoder.layer.0.attention.self.value.bias', 'roberta.bert.encoder.layer.0.attention.self.value.weight', 'roberta.bert.encoder.layer.0.intermediate.dense.bias', 'roberta.bert.encoder.layer.0.intermediate.dense.weight', 'roberta.bert.encoder.layer.0.output.LayerNorm.bias', 'roberta.bert.encoder.layer.0.output.LayerNorm.weight', 'roberta.bert.encoder.layer.0.output.dense.bias', 'roberta.bert.encoder.layer.0.output.dense.weight', 'roberta.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.1.attention.output.dense.bias', 'roberta.bert.encoder.layer.1.attention.output.dense.weight', 'roberta.bert.encoder.layer.1.attention.self.key.bias', 'roberta.bert.encoder.layer.1.attention.self.key.weight', 'roberta.bert.encoder.layer.1.attention.self.query.bias', 'roberta.bert.encoder.layer.1.attention.self.query.weight', 'roberta.bert.encoder.layer.1.attention.self.value.bias', 'roberta.bert.encoder.layer.1.attention.self.value.weight', 'roberta.bert.encoder.layer.1.intermediate.dense.bias', 'roberta.bert.encoder.layer.1.intermediate.dense.weight', 'roberta.bert.encoder.layer.1.output.LayerNorm.bias', 'roberta.bert.encoder.layer.1.output.LayerNorm.weight', 'roberta.bert.encoder.layer.1.output.dense.bias', 'roberta.bert.encoder.layer.1.output.dense.weight', 'roberta.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.10.attention.output.dense.bias', 'roberta.bert.encoder.layer.10.attention.output.dense.weight', 'roberta.bert.encoder.layer.10.attention.self.key.bias', 'roberta.bert.encoder.layer.10.attention.self.key.weight', 'roberta.bert.encoder.layer.10.attention.self.query.bias', 'roberta.bert.encoder.layer.10.attention.self.query.weight', 'roberta.bert.encoder.layer.10.attention.self.value.bias', 'roberta.bert.encoder.layer.10.attention.self.value.weight', 'roberta.bert.encoder.layer.10.intermediate.dense.bias', 'roberta.bert.encoder.layer.10.intermediate.dense.weight', 'roberta.bert.encoder.layer.10.output.LayerNorm.bias', 'roberta.bert.encoder.layer.10.output.LayerNorm.weight', 'roberta.bert.encoder.layer.10.output.dense.bias', 'roberta.bert.encoder.layer.10.output.dense.weight', 'roberta.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.11.attention.output.dense.bias', 'roberta.bert.encoder.layer.11.attention.output.dense.weight', 'roberta.bert.encoder.layer.11.attention.self.key.bias', 'roberta.bert.encoder.layer.11.attention.self.key.weight', 'roberta.bert.encoder.layer.11.attention.self.query.bias', 'roberta.bert.encoder.layer.11.attention.self.query.weight', 'roberta.bert.encoder.layer.11.attention.self.value.bias', 'roberta.bert.encoder.layer.11.attention.self.value.weight', 'roberta.bert.encoder.layer.11.intermediate.dense.bias', 'roberta.bert.encoder.layer.11.intermediate.dense.weight', 'roberta.bert.encoder.layer.11.output.LayerNorm.bias', 'roberta.bert.encoder.layer.11.output.LayerNorm.weight', 'roberta.bert.encoder.layer.11.output.dense.bias', 'roberta.bert.encoder.layer.11.output.dense.weight', 'roberta.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.2.attention.output.dense.bias', 'roberta.bert.encoder.layer.2.attention.output.dense.weight', 'roberta.bert.encoder.layer.2.attention.self.key.bias', 'roberta.bert.encoder.layer.2.attention.self.key.weight', 'roberta.bert.encoder.layer.2.attention.self.query.bias', 'roberta.bert.encoder.layer.2.attention.self.query.weight', 'roberta.bert.encoder.layer.2.attention.self.value.bias', 'roberta.bert.encoder.layer.2.attention.self.value.weight', 'roberta.bert.encoder.layer.2.intermediate.dense.bias', 'roberta.bert.encoder.layer.2.intermediate.dense.weight', 'roberta.bert.encoder.layer.2.output.LayerNorm.bias', 'roberta.bert.encoder.layer.2.output.LayerNorm.weight', 'roberta.bert.encoder.layer.2.output.dense.bias', 'roberta.bert.encoder.layer.2.output.dense.weight', 'roberta.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.3.attention.output.dense.bias', 'roberta.bert.encoder.layer.3.attention.output.dense.weight', 'roberta.bert.encoder.layer.3.attention.self.key.bias', 'roberta.bert.encoder.layer.3.attention.self.key.weight', 'roberta.bert.encoder.layer.3.attention.self.query.bias', 'roberta.bert.encoder.layer.3.attention.self.query.weight', 'roberta.bert.encoder.layer.3.attention.self.value.bias', 'roberta.bert.encoder.layer.3.attention.self.value.weight', 'roberta.bert.encoder.layer.3.intermediate.dense.bias', 'roberta.bert.encoder.layer.3.intermediate.dense.weight', 'roberta.bert.encoder.layer.3.output.LayerNorm.bias', 'roberta.bert.encoder.layer.3.output.LayerNorm.weight', 'roberta.bert.encoder.layer.3.output.dense.bias', 'roberta.bert.encoder.layer.3.output.dense.weight', 'roberta.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.4.attention.output.dense.bias', 'roberta.bert.encoder.layer.4.attention.output.dense.weight', 'roberta.bert.encoder.layer.4.attention.self.key.bias', 'roberta.bert.encoder.layer.4.attention.self.key.weight', 'roberta.bert.encoder.layer.4.attention.self.query.bias', 'roberta.bert.encoder.layer.4.attention.self.query.weight', 'roberta.bert.encoder.layer.4.attention.self.value.bias', 'roberta.bert.encoder.layer.4.attention.self.value.weight', 'roberta.bert.encoder.layer.4.intermediate.dense.bias', 'roberta.bert.encoder.layer.4.intermediate.dense.weight', 'roberta.bert.encoder.layer.4.output.LayerNorm.bias', 'roberta.bert.encoder.layer.4.output.LayerNorm.weight', 'roberta.bert.encoder.layer.4.output.dense.bias', 'roberta.bert.encoder.layer.4.output.dense.weight', 'roberta.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.5.attention.output.dense.bias', 'roberta.bert.encoder.layer.5.attention.output.dense.weight', 'roberta.bert.encoder.layer.5.attention.self.key.bias', 'roberta.bert.encoder.layer.5.attention.self.key.weight', 'roberta.bert.encoder.layer.5.attention.self.query.bias', 'roberta.bert.encoder.layer.5.attention.self.query.weight', 'roberta.bert.encoder.layer.5.attention.self.value.bias', 'roberta.bert.encoder.layer.5.attention.self.value.weight', 'roberta.bert.encoder.layer.5.intermediate.dense.bias', 'roberta.bert.encoder.layer.5.intermediate.dense.weight', 'roberta.bert.encoder.layer.5.output.LayerNorm.bias', 'roberta.bert.encoder.layer.5.output.LayerNorm.weight', 'roberta.bert.encoder.layer.5.output.dense.bias', 'roberta.bert.encoder.layer.5.output.dense.weight', 'roberta.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.6.attention.output.dense.bias', 'roberta.bert.encoder.layer.6.attention.output.dense.weight', 'roberta.bert.encoder.layer.6.attention.self.key.bias', 'roberta.bert.encoder.layer.6.attention.self.key.weight', 'roberta.bert.encoder.layer.6.attention.self.query.bias', 'roberta.bert.encoder.layer.6.attention.self.query.weight', 'roberta.bert.encoder.layer.6.attention.self.value.bias', 'roberta.bert.encoder.layer.6.attention.self.value.weight', 'roberta.bert.encoder.layer.6.intermediate.dense.bias', 'roberta.bert.encoder.layer.6.intermediate.dense.weight', 'roberta.bert.encoder.layer.6.output.LayerNorm.bias', 'roberta.bert.encoder.layer.6.output.LayerNorm.weight', 'roberta.bert.encoder.layer.6.output.dense.bias', 'roberta.bert.encoder.layer.6.output.dense.weight', 'roberta.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.7.attention.output.dense.bias', 'roberta.bert.encoder.layer.7.attention.output.dense.weight', 'roberta.bert.encoder.layer.7.attention.self.key.bias', 'roberta.bert.encoder.layer.7.attention.self.key.weight', 'roberta.bert.encoder.layer.7.attention.self.query.bias', 'roberta.bert.encoder.layer.7.attention.self.query.weight', 'roberta.bert.encoder.layer.7.attention.self.value.bias', 'roberta.bert.encoder.layer.7.attention.self.value.weight', 'roberta.bert.encoder.layer.7.intermediate.dense.bias', 'roberta.bert.encoder.layer.7.intermediate.dense.weight', 'roberta.bert.encoder.layer.7.output.LayerNorm.bias', 'roberta.bert.encoder.layer.7.output.LayerNorm.weight', 'roberta.bert.encoder.layer.7.output.dense.bias', 'roberta.bert.encoder.layer.7.output.dense.weight', 'roberta.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.8.attention.output.dense.bias', 'roberta.bert.encoder.layer.8.attention.output.dense.weight', 'roberta.bert.encoder.layer.8.attention.self.key.bias', 'roberta.bert.encoder.layer.8.attention.self.key.weight', 'roberta.bert.encoder.layer.8.attention.self.query.bias', 'roberta.bert.encoder.layer.8.attention.self.query.weight', 'roberta.bert.encoder.layer.8.attention.self.value.bias', 'roberta.bert.encoder.layer.8.attention.self.value.weight', 'roberta.bert.encoder.layer.8.intermediate.dense.bias', 'roberta.bert.encoder.layer.8.intermediate.dense.weight', 'roberta.bert.encoder.layer.8.output.LayerNorm.bias', 'roberta.bert.encoder.layer.8.output.LayerNorm.weight', 'roberta.bert.encoder.layer.8.output.dense.bias', 'roberta.bert.encoder.layer.8.output.dense.weight', 'roberta.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.bert.encoder.layer.9.attention.output.dense.bias', 'roberta.bert.encoder.layer.9.attention.output.dense.weight', 'roberta.bert.encoder.layer.9.attention.self.key.bias', 'roberta.bert.encoder.layer.9.attention.self.key.weight', 'roberta.bert.encoder.layer.9.attention.self.query.bias', 'roberta.bert.encoder.layer.9.attention.self.query.weight', 'roberta.bert.encoder.layer.9.attention.self.value.bias', 'roberta.bert.encoder.layer.9.attention.self.value.weight', 'roberta.bert.encoder.layer.9.intermediate.dense.bias', 'roberta.bert.encoder.layer.9.intermediate.dense.weight', 'roberta.bert.encoder.layer.9.output.LayerNorm.bias', 'roberta.bert.encoder.layer.9.output.LayerNorm.weight', 'roberta.bert.encoder.layer.9.output.dense.bias', 'roberta.bert.encoder.layer.9.output.dense.weight', 'roberta.bert.pooler.dense.bias', 'roberta.bert.pooler.dense.weight', 'roberta.classifier.0.bias', 'roberta.classifier.0.weight', 'roberta.classifier.3.bias', 'roberta.classifier.3.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " Train Loss: 0.5424\n",
      " Val Loss: 0.3457\n",
      " Val Acc: 0.8700\n",
      "------------------------------\n",
      "Epoch 2\n",
      " Train Loss: 0.2719\n",
      " Val Loss: 0.2261\n",
      " Val Acc: 0.9225\n",
      "------------------------------\n",
      "Epoch 3\n",
      " Train Loss: 0.2007\n",
      " Val Loss: 0.2413\n",
      " Val Acc: 0.9125\n",
      "------------------------------\n",
      "Epoch 4\n",
      " Train Loss: 0.1568\n",
      " Val Loss: 0.2308\n",
      " Val Acc: 0.9225\n",
      "------------------------------\n",
      "RoBERTa Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9818    0.8526    0.9127       190\n",
      "           1     0.8809    0.9857    0.9303       210\n",
      "\n",
      "    accuracy                         0.9225       400\n",
      "   macro avg     0.9313    0.9192    0.9215       400\n",
      "weighted avg     0.9288    0.9225    0.9219       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "# === Load data including personality features ===\n",
    "texts = data['cleaned_text'].tolist()\n",
    "labels = data['true_class'].map({'suicide': 1, 'non-suicide': 0})\n",
    "personality_features = data[[\"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "personality_features = torch.tensor(personality_features, dtype=torch.float32)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mental/mental-roberta-base')\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    texts,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded_data['input_ids']\n",
    "attention_masks = encoded_data['attention_mask']\n",
    "labels = torch.tensor(labels.values, dtype=torch.long) \n",
    "\n",
    "# Dataset with text tokens + personality features\n",
    "class RoBertaWithPersonalityDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, personality_feats, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.personality_feats = personality_feats\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.input_ids[idx],\n",
    "                self.attention_masks[idx],\n",
    "                self.personality_feats[idx],\n",
    "                self.labels[idx])\n",
    "    \n",
    "dataset = RoBertaWithPersonalityDataset(input_ids, attention_masks, personality_features, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    batch_size=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ===== Custom model combining RoBERTa + Personality Features =====\n",
    "class RoBertaWithPersonality(RobertaPreTrainedModel):\n",
    "    def __init__(self, config, personality_feat_dim=3, num_labels=2):\n",
    "        super().__init__(config)\n",
    "        self.bert = RobertaModel.from_pretrained(\"mental/mental-roberta-base\", config=config)\n",
    "        bert_hidden_size = config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert_hidden_size + personality_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, personality_feats, labels=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = bert_outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "        combined = torch.cat((cls_output, personality_feats), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ===== Config =====\n",
    "config = AutoConfig.from_pretrained(\n",
    "    'mental/mental-roberta-base',\n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.3,\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "\n",
    "model = RoBertaWithPersonality.from_pretrained(\"mental/mental-roberta-base\", config=config)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# ===== Training Loop =====\n",
    "for epoch in range(4):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_personality, b_labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "        logits = model(b_input_ids, attention_mask=b_input_mask, personality_feats=b_personality)\n",
    "\n",
    "        loss = criterion(logits, b_labels)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_labels, val_preds, val_probs = [], [], []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        b_input_ids, b_input_mask, b_personality, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, attention_mask=b_input_mask, personality_feats=b_personality)\n",
    "            loss = criterion(logits, b_labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Probabilities for ROC-AUC\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "            val_probs.extend(probs)\n",
    "\n",
    "            predictions = np.argmax(logits.cpu().numpy(), axis=1)\n",
    "            val_labels.extend(label_ids)\n",
    "            val_preds.extend(predictions)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\" Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\" Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\" Val Acc: {val_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"RoBERTa Results:\")\n",
    "print(classification_report(val_labels, val_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe6c762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-suicide', 'Suicide'], yticklabels=['Non-suicide', 'Suicide'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix (Mental-RoBERTa) - relabeled + personality')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f07d48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 31\n",
      "                                                  text  true_label  \\\n",
      "5    i feel so devastated and i miss them its alway...           0   \n",
      "58   Lost one of my employees to suicide.I realize ...           0   \n",
      "63   I am a bit down I don't really know why .like ...           0   \n",
      "77   Apparently it gets better Listen, a few weeks ...           0   \n",
      "78   Finding hope. I have learned to find hope that...           0   \n",
      "80   relationships suck assi just want to talk to s...           1   \n",
      "96   I ruined my family.(I have no idea of where to...           1   \n",
      "115  i don't even think I'm going to make it to spr...           0   \n",
      "116  I lost my two best friends I don't know what t...           0   \n",
      "122  I wanna off myself so bad so fucking bad what ...           0   \n",
      "\n",
      "     pred_label true_label_name pred_label_name  \n",
      "5             1     non-suicide         suicide  \n",
      "58            1     non-suicide         suicide  \n",
      "63            1     non-suicide         suicide  \n",
      "77            1     non-suicide         suicide  \n",
      "78            1     non-suicide         suicide  \n",
      "80            0         suicide     non-suicide  \n",
      "96            0         suicide     non-suicide  \n",
      "115           1     non-suicide         suicide  \n",
      "116           1     non-suicide         suicide  \n",
      "122           1     non-suicide         suicide  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\2637728455.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10624\\2637728455.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state dict and tokenizer saved to ../saved_models/mental_roberta_personality\n"
     ]
    }
   ],
   "source": [
    "#save misclassified samples\n",
    "val_indices = val_dataset.indices if hasattr(val_dataset, 'indices') else np.arange(len(val_dataset))\n",
    "\n",
    "val_texts = [texts[i] for i in val_indices]\n",
    "val_true_labels = [labels[i].item() for i in val_indices]  \n",
    "val_pred_labels = val_preds  \n",
    "\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'text': val_texts,\n",
    "    'true_label': val_true_labels,\n",
    "    'pred_label': val_pred_labels\n",
    "})\n",
    "\n",
    "# Filter misclassified samples\n",
    "misclassified_df = val_df[val_df['true_label'] != val_df['pred_label']]\n",
    "\n",
    "# Optionally, map label numbers back to class names\n",
    "label_map = {0: 'non-suicide', 1: 'suicide'}\n",
    "misclassified_df['true_label_name'] = misclassified_df['true_label'].map(label_map)\n",
    "misclassified_df['pred_label_name'] = misclassified_df['pred_label'].map(label_map)\n",
    "\n",
    "print(f\"Number of misclassified samples: {len(misclassified_df)}\")\n",
    "print(misclassified_df.head(10))  # view first 10 misclassified samples\n",
    "\n",
    "# Save the model\n",
    "output_dir = \"../saved_models/mental_roberta_personality\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "misclassified_df.to_csv(output_dir + '/misclassified_samples.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Model state dict and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a94dab",
   "metadata": {},
   "source": [
    "### 5\n",
    "### Testing results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45085af4",
   "metadata": {},
   "source": [
    "#### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b246cdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[393 107]\n",
      " [  5 495]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-suicide       0.99      0.79      0.88       500\n",
      "     Suicide       0.82      0.99      0.90       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.90      0.89      0.89      1000\n",
      "weighted avg       0.90      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa+ Original Labels\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('../dataset/testing_1000_samples_2.csv')\n",
    "\n",
    "# Map string labels to integers\n",
    "label_map = {\"non-suicide\": 0, \"suicide\": 1}\n",
    "true_labels_int = df['true_class'].map(label_map).values\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Load RoBERTasuicide classifier =====\n",
    "model_dir = \"../saved_models/mental_roberta_raw\"\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "bert_model.to(device).eval()\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# ===== Parameters =====\n",
    "batch_size = 16  # adjust based on GPU memory\n",
    "final_predictions = []\n",
    "\n",
    "# ===== Batching for RoBERTa inference =====\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['cleaned_text'][i:i+batch_size].tolist()\n",
    "    \n",
    "    # RoBERTa tokenization\n",
    "    encodings = bert_tokenizer(\n",
    "        batch_texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    # RoBERTa predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    final_predictions.extend(batch_preds)\n",
    "    \n",
    "    # Free GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Evaluation =====\n",
    "df['Predicted_Label'] = [\"non-suicide\" if p==0 else \"suicide\" for p in final_predictions]\n",
    "\n",
    "cm = confusion_matrix(true_labels_int, final_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels_int, final_predictions, target_names=[\"Non-suicide\", \"Suicide\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5c16d",
   "metadata": {},
   "source": [
    "#### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aeb2142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Documents\\Master_Project\\Suicide-Ideation-Detection-in-Social-Media-Using-Personality-Traits-main\\venv\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[394 106]\n",
      " [  5 495]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-suicide       0.99      0.79      0.88       500\n",
      "     Suicide       0.82      0.99      0.90       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.91      0.89      0.89      1000\n",
      "weighted avg       0.91      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa + Original Labels + Personality Evaluation \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('../dataset/testing_1000_samples_2.csv')\n",
    "true_labels = df['true_class'].map({'non-suicide':0, 'suicide':1}).values\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Load personality features =====\n",
    "personality_features = df[[\"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "personality_features = torch.tensor(personality_features, dtype=torch.float32).to(device)\n",
    "\n",
    "# ===== Tokenizer =====\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('../saved_models/mental_roberta_raw_personality')\n",
    "\n",
    "class RoBertaWithPersonality(RobertaPreTrainedModel):\n",
    "    def __init__(self, config, personality_feat_dim=3, num_labels=2):\n",
    "        super().__init__(config)\n",
    "        self.bert = RobertaModel.from_pretrained(\"mental/mental-roberta-base\", config=config)\n",
    "        bert_hidden_size = config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert_hidden_size + personality_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, personality_feats, labels=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = bert_outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "        combined = torch.cat((cls_output, personality_feats), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# ===== Load pretrained RoBERTa + Personality model =====\n",
    "config = AutoConfig.from_pretrained('mental/mental-roberta-base', num_labels=2)\n",
    "bert_personality_model = RoBertaWithPersonality.from_pretrained('../saved_models/mental_roberta_raw_personality', config=config)\n",
    "bert_personality_model.to(device).eval()\n",
    "\n",
    "# ===== Parameters =====\n",
    "batch_size = 16\n",
    "final_predictions = []\n",
    "\n",
    "# ===== Batching for RoBERTa + Personality inference =====\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['cleaned_text'][i:i+batch_size].tolist()\n",
    "    batch_personality = personality_features[i:i+batch_size]\n",
    "\n",
    "    # RoBERTa tokenization\n",
    "    encodings = bert_tokenizer(\n",
    "        batch_texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "    # RoBERTa + Personality predictions\n",
    "    with torch.no_grad():\n",
    "        logits = bert_personality_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            personality_feats=batch_personality\n",
    "        )\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        final_predictions.extend(batch_preds)\n",
    "\n",
    "    # Free GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Evaluation =====\n",
    "df['Predicted_Label'] = [\"non-suicide\" if p==0 else \"suicide\" for p in final_predictions]\n",
    "\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, final_predictions, target_names=[\"Non-suicide\",\"Suicide\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49fbd7a",
   "metadata": {},
   "source": [
    "#### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9277fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[469  31]\n",
      " [ 26 474]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-suicide       0.95      0.94      0.94       500\n",
      "     Suicide       0.94      0.95      0.94       500\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.94      0.94      0.94      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa + Relabeled Data Evaluation\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('../dataset/testing_1000_samples_2.csv')\n",
    "\n",
    "# Map string labels to integers\n",
    "label_map = {\"non-suicide\": 0, \"suicide\": 1}\n",
    "true_labels_int = df['true_class'].map(label_map).values\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Load RoBERTa suicide classifier =====\n",
    "model_dir = \"../saved_models/mental_roberta_relabeled\"\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "bert_model.to(device).eval()\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# ===== Parameters =====\n",
    "batch_size = 16  # adjust based on GPU memory\n",
    "final_predictions = []\n",
    "\n",
    "# ===== Batching for RoBERTa inference =====\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['cleaned_text'][i:i+batch_size].tolist()\n",
    "    \n",
    "    # RoBERTa tokenization\n",
    "    encodings = bert_tokenizer(\n",
    "        batch_texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    # RoBERTa predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    final_predictions.extend(batch_preds)\n",
    "    \n",
    "    # Free GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Evaluation =====\n",
    "df['Predicted_Label'] = [\"non-suicide\" if p==0 else \"suicide\" for p in final_predictions]\n",
    "\n",
    "cm = confusion_matrix(true_labels_int, final_predictions)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels_int, final_predictions, target_names=[\"Non-suicide\", \"Suicide\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c774b",
   "metadata": {},
   "source": [
    "#### 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e00f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[446  54]\n",
      " [ 14 486]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-suicide       0.97      0.89      0.93       500\n",
      "     Suicide       0.90      0.97      0.93       500\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa + Relabeled Data + Personality Evaluation \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('../dataset/testing_1000_samples_2.csv')\n",
    "true_labels = df['true_class'].map({'non-suicide':0, 'suicide':1}).values\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Load personality features =====\n",
    "personality_features = df[[\"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "personality_features = torch.tensor(personality_features, dtype=torch.float32).to(device)\n",
    "\n",
    "# ===== Tokenizer =====\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('../saved_models/mental_roberta_personality')\n",
    "\n",
    "class RoBertaWithPersonality(RobertaPreTrainedModel):\n",
    "    def __init__(self, config, personality_feat_dim=3, num_labels=2):\n",
    "        super().__init__(config)\n",
    "        self.bert = RobertaModel.from_pretrained(\"mental/mental-roberta-base\", config=config)\n",
    "        bert_hidden_size = config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert_hidden_size + personality_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, personality_feats, labels=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = bert_outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "        combined = torch.cat((cls_output, personality_feats), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        return logits\n",
    "# ===== Load pretrained RoBERTa + Personality model =====\n",
    "config = AutoConfig.from_pretrained('mental/mental-roberta-base', num_labels=2)\n",
    "bert_personality_model = RoBertaWithPersonality.from_pretrained('../saved_models/mental_roberta_personality', config=config)\n",
    "bert_personality_model.to(device).eval()\n",
    "\n",
    "# ===== Parameters =====\n",
    "batch_size = 16\n",
    "final_predictions = []\n",
    "\n",
    "# ===== Batching for RoBERTa + Personality inference =====\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['cleaned_text'][i:i+batch_size].tolist()\n",
    "    batch_personality = personality_features[i:i+batch_size]\n",
    "\n",
    "    # RoBERTa tokenization\n",
    "    encodings = bert_tokenizer(\n",
    "        batch_texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "    # RoBERTa + Personality predictions\n",
    "    with torch.no_grad():\n",
    "        logits = bert_personality_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            personality_feats=batch_personality\n",
    "        )\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        final_predictions.extend(batch_preds)\n",
    "\n",
    "\n",
    "\n",
    "    # Free GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Evaluation =====\n",
    "df['Predicted_Label'] = [\"non-suicide\" if p==0 else \"suicide\" for p in final_predictions]\n",
    "\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, final_predictions, target_names=[\"Non-suicide\",\"Suicide\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91b426",
   "metadata": {},
   "source": [
    "#### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfff4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[477  23]\n",
      " [ 43 457]]\n",
      "\n",
      "False Positive Rate (FPR): 0.0460\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-suicide       0.92      0.95      0.94       500\n",
      "     Suicide       0.95      0.91      0.93       500\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa + Relabeled + NLI Evaluation \n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('../dataset/testing_1000_samples_2.csv')\n",
    "true_labels = df['true_class'].values  \n",
    "\n",
    "label_map = {\"non-suicide\": 0, \"suicide\": 1}\n",
    "true_labels_int = df['true_class'].map(label_map).values\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Load RoBERTa suicide classifier =====\n",
    "model_dir = \"../saved_models/mental_roberta_relabeled\"\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "bert_model.to(device).eval()\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# ===== Load pretrained NLI model =====\n",
    "nli_model_name = \"tasksource/deberta-small-long-nli\"\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name).to(device).eval()\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
    "\n",
    "# ===== Negative hypotheses to detect supportive/awareness posts =====\n",
    "\n",
    "negative_hypotheses = [\n",
    "    \"The author discusses suicide in general, awareness, or prevention, not personal suicidal thoughts.\",\n",
    "    \"The post shares support, resources, or information, not the author's own suicidal intent.\",\n",
    "    \"The author reflects to inspire or thank others, not describing current suicidal thoughts.\"\n",
    "]\n",
    "\n",
    "# ===== Helper: NLI negative filtering =====\n",
    "def nli_negative_filter(post, threshold=0.65):\n",
    "    max_neg_entail_prob = 0\n",
    "    for hypo in negative_hypotheses:\n",
    "        inputs = nli_tokenizer(\n",
    "            post,\n",
    "            hypo,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = nli_model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=-1)[0]  # [entail, neutral, contradict]\n",
    "            entail_prob = probs[0].item()  # entailment\n",
    "        max_neg_entail_prob = max(max_neg_entail_prob, entail_prob)\n",
    "    \n",
    "    # If the max negative entailment is high, the post is likely non-suicidal\n",
    "    return max_neg_entail_prob >= threshold\n",
    "\n",
    "# ===== Parameters =====\n",
    "batch_size = 16  # adjust based on GPU memory\n",
    "final_predictions = []\n",
    "\n",
    "# ===== Batching for RoBERTa inference =====\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['cleaned_text'][i:i+batch_size].tolist()\n",
    "    \n",
    "    # RoBERTa tokenization\n",
    "    encodings = bert_tokenizer(\n",
    "        batch_texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    # RoBERTa predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    # Apply NLI negative filtering\n",
    "    for text, pred in zip(batch_texts, batch_preds):\n",
    "        if pred == 1:  # initially predicted as suicide\n",
    "            is_negative = nli_negative_filter(text, threshold=0.65)\n",
    "            final_predictions.append(0 if is_negative else 1)\n",
    "        else:\n",
    "            final_predictions.append(pred)\n",
    "\n",
    "    # Free GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Evaluation =====\n",
    "\n",
    "df['Predicted_Label'] = [\"non-suicide\" if p==0 else \"suicide\" for p in final_predictions]\n",
    "\n",
    "cm = confusion_matrix(true_labels_int, final_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nFalse Positive Rate (FPR): {fpr:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels_int, final_predictions, target_names=[\"Non-suicide\", \"Suicide\"], zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcbec9",
   "metadata": {},
   "source": [
    "#### 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1af7326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../saved_models/mental_roberta_personality and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[448  52]\n",
      " [ 16 484]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-suicide       0.97      0.90      0.93       500\n",
      "     Suicide       0.90      0.97      0.93       500\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RoBERTa + Relabeled + Personality + NLI Evaluation \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('../dataset/testing_1000_samples_2.csv')\n",
    "true_labels = df['true_class'].map({'non-suicide':0, 'suicide':1}).values\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Load personality features =====\n",
    "personality_features = df[[\"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "personality_features = torch.tensor(personality_features, dtype=torch.float32).to(device)\n",
    "\n",
    "model_dir = \"../saved_models/mental_roberta_personality\"\n",
    "# ===== Tokenizer =====\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "class RoBertaWithPersonality(RobertaPreTrainedModel):\n",
    "    def __init__(self, config, personality_feat_dim=3, num_labels=2):\n",
    "        super().__init__(config)\n",
    "        self.bert = RobertaModel.from_pretrained(model_dir, config=config)\n",
    "        bert_hidden_size = config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert_hidden_size + personality_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, personality_feats, labels=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = bert_outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "        combined = torch.cat((cls_output, personality_feats), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# ===== Load pretrained RoBERTa + Personality model =====\n",
    "config = AutoConfig.from_pretrained(model_dir, num_labels=2)\n",
    "bert_personality_model = RoBertaWithPersonality.from_pretrained(model_dir, config=config)\n",
    "bert_personality_model.to(device).eval()\n",
    "\n",
    "# ===== Load pretrained NLI model =====\n",
    "nli_model_name = \"tasksource/deberta-small-long-nli\"\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name).to(device).eval()\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
    "\n",
    "# ===== Negative hypotheses for NLI filtering =====\n",
    "negative_hypotheses = [\n",
    "    \"The author discusses suicide in general, awareness, or prevention, not personal suicidal thoughts.\",\n",
    "    \"The post shares support, resources, or hotlines, not the author's own suicidal intent.\",\n",
    "    \"The author reflects to inspire or thank others, not describing current suicidal thoughts.\"\n",
    "]\n",
    "\n",
    "# ===== Helper: NLI negative filtering =====\n",
    "def nli_negative_filter(post, threshold=0.65):\n",
    "    max_neg_entail_prob = 0\n",
    "    for hypo in negative_hypotheses:\n",
    "        inputs = nli_tokenizer(post, hypo, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = nli_model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=-1)[0]  \n",
    "            entail_prob = probs[0].item()  # entailment probability\n",
    "        max_neg_entail_prob = max(max_neg_entail_prob, entail_prob)\n",
    "    return max_neg_entail_prob >= threshold\n",
    "\n",
    "# ===== Parameters =====\n",
    "batch_size = 16\n",
    "final_predictions = []\n",
    "\n",
    "# ===== Batching for RoBERTa + Personality inference =====\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['cleaned_text'][i:i+batch_size].tolist()\n",
    "    batch_personality = personality_features[i:i+batch_size]\n",
    "\n",
    "    # RoBERTa tokenization\n",
    "    encodings = bert_tokenizer(\n",
    "        batch_texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "    # RoBERTa+ Personality predictions\n",
    "    with torch.no_grad():\n",
    "        logits = bert_personality_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            personality_feats=batch_personality\n",
    "        )\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "    # Apply NLI negative filtering\n",
    "    for text, pred in zip(batch_texts, batch_preds):\n",
    "        if pred == 1:  # initially predicted as suicide\n",
    "            is_negative = nli_negative_filter(text, threshold=0.65)\n",
    "            final_predictions.append(0 if is_negative else 1)\n",
    "        else:\n",
    "            final_predictions.append(pred)\n",
    "\n",
    "    # Free GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Evaluation =====\n",
    "df['Predicted_Label'] = [\"non-suicide\" if p==0 else \"suicide\" for p in final_predictions]\n",
    "\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, final_predictions, target_names=[\"Non-suicide\",\"Suicide\"], zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf2c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance dataset size: 1000\n",
      "FP test dataset size: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../saved_models/mental_roberta_personality and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing thresholds for dual optimization (performance + FP reduction)...\n",
      "Testing threshold: 0.60\n",
      "  Performance - F1: 0.9238, FP: 51\n",
      "  FP Test - FPR: 0.3146, FP: 28\n",
      "Testing threshold: 0.61\n",
      "  Performance - F1: 0.9250, FP: 52\n",
      "  FP Test - FPR: 0.3146, FP: 28\n",
      "Testing threshold: 0.62\n",
      "  Performance - F1: 0.9282, FP: 52\n",
      "  FP Test - FPR: 0.3146, FP: 28\n",
      "Testing threshold: 0.63\n",
      "  Performance - F1: 0.9302, FP: 52\n",
      "  FP Test - FPR: 0.3146, FP: 28\n",
      "Testing threshold: 0.64\n",
      "  Performance - F1: 0.9333, FP: 52\n",
      "  FP Test - FPR: 0.3258, FP: 29\n",
      "Testing threshold: 0.65\n",
      "  Performance - F1: 0.9344, FP: 52\n",
      "  FP Test - FPR: 0.3258, FP: 29\n",
      "Testing threshold: 0.66\n",
      "  Performance - F1: 0.9344, FP: 52\n",
      "  FP Test - FPR: 0.3371, FP: 30\n",
      "Testing threshold: 0.67\n",
      "  Performance - F1: 0.9335, FP: 53\n",
      "  FP Test - FPR: 0.3483, FP: 31\n",
      "Testing threshold: 0.68\n",
      "  Performance - F1: 0.9335, FP: 53\n",
      "  FP Test - FPR: 0.3708, FP: 33\n",
      "Testing threshold: 0.69\n",
      "  Performance - F1: 0.9326, FP: 54\n",
      "  FP Test - FPR: 0.3820, FP: 34\n",
      "Testing threshold: 0.70\n",
      "  Performance - F1: 0.9336, FP: 54\n",
      "  FP Test - FPR: 0.3820, FP: 34\n",
      "Selected threshold: 0.65\n",
      "F1 Score: 0.9343629343629344\n",
      "False Positives: 29\n",
      "\n",
      "============================================================\n",
      "MULTI-OBJECTIVE THRESHOLD OPTIMIZATION RESULTS\n",
      "============================================================\n",
      "    threshold  combined_score  f1_score     fpr  fp_count  performance_fp\n",
      "0        0.60          0.8761    0.9238  0.3146        28              51\n",
      "1        0.61          0.8771    0.9250  0.3146        28              52\n",
      "2        0.62          0.8796    0.9282  0.3146        28              52\n",
      "3        0.63          0.8813    0.9302  0.3146        28              52\n",
      "4        0.64          0.8815    0.9333  0.3258        29              52\n",
      "5        0.65          0.8823    0.9344  0.3258        29              52\n",
      "6        0.66          0.8801    0.9344  0.3371        30              52\n",
      "7        0.67          0.8771    0.9335  0.3483        31              53\n",
      "8        0.68          0.8726    0.9335  0.3708        33              53\n",
      "9        0.69          0.8696    0.9326  0.3820        34              54\n",
      "10       0.70          0.8705    0.9336  0.3820        34              54\n",
      "\n",
      "Best threshold: 0.65\n",
      "Combined score: 0.8823\n",
      "Performance F1: 0.9344\n",
      "FP Test FPR: 0.3258\n",
      "FP Count: 29\n",
      "\n",
      "Final evaluation with optimal threshold: 0.65\n",
      "\n",
      "Performance Dataset Results:\n",
      "F1 Score: 0.9344\n",
      "Precision: 0.9030\n",
      "Recall: 0.9680\n",
      "False Positives: 52\n",
      "\n",
      "FP Test Dataset Results:\n",
      "False Positive Rate: 0.3258\n",
      "False Positives: 29\n",
      "True Negatives: 60\n",
      "\n",
      "========================================\n",
      "COMPARISON WITH BASELINE (NO NLI FILTERING)\n",
      "========================================\n",
      "Performance Baseline F1: 0.0000 → With NLI: 0.9344\n",
      "Performance Baseline FP: 0 → With NLI: 52\n",
      "FP Test Baseline FP: 36 → With NLI: 29\n",
      "FP Reduction: 19.4%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAANgRJREFUeJzt3Qt8FOW5x/EnF5JwSxACCTcJAop4ASUkBa1VweLloGiPB68gVjxWUCv1AqJBsYitluLBVNQDeg5ooRypWrWopVpLoYBQQLwgCEIEkoBKwjWBZM7necNsdpNNSMjuTvLu7/v5DLs7OzM7O0nY/77v887EOI7jCAAAgCVivd4BAACAUCLcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYJV6iTHl5uezcuVNat24tMTExXu8OAACoAz0t3759+6RTp04SG1t720zUhRsNNl27dvV6NwAAwAnIy8uTLl261LpM1IUbbbFxD05ycrLXuwMAAOqguLjYNE64n+O1ibpw43ZFabAh3AAA0LTUpaSEgmIAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArBJ1F84E0DQ5jiNl5Y6UOY6Ul4scLS83t2XH5pf73TZFsTExEhcb43crEhsbI3HHHuu1AivvH//CgUA0I9wAljtSVi6Hj5TJoSNlUnKk3Nyax6UV8w4fqXjeXUYfVyxbJiVHy32BoqzMDRbHHh8LEkfLKoNFmSMVz7tTleDhP9/djgko5Y4c9Q8ofuu6yzfRzBIWbtDRIBQbe+x+QDDS24rA5M7zBaZaQlTFNiTgeZ0fc2x77nz3uaYYsdz3UnHsgodH33HwW6by+AYew8ptBB5v33rBQqrfNoP9XCp/ZhXzK/4uKv5OKv/WKv8+av6blMq/tbr+Tfqt4/83WfvfccXfvX7h0PV1uR7tW8qkK/p49nMm3AAe0P8YKsOEO1UPHgFhxC+I6POHj7q35XI44LHeVgYW/Q8qGugHRHxsrPnwaGocv5apuvy4NOgdNWnPESmLxB4C9bP3YBvxEuEG1tIPC/1g15aL0qPlUlpWLkfKHHM/YJ7vOXeeE2SeLudIaVmZbxvV13Vq2F7FfQ0qbojReV5o3ixOkprFHrt1p1hpnhAnSfFxknTstnlCrLlNiI+V+GPfQt1b37dbvxaBwG+iFd82NWgEfMs9toxvO1VaByq3JTVv+9itbqNq64MtXTX6e6u5xf8btgYe/2/oemvm+X0rr1gu8Bu+f1ed+43a/1u+eZ2qLWn+rW9mXwK/zTfl7j/dZfP+nOMdy4pl/I+N/zGsenx9x7ZaF6lUf50qrS++n0GVn6H/tqq2yJm/l7jAvwv3+fi4wL8r07Jn/l5iJa5Kq5zvb6nK35e+hv79+lqqqv6N+rU6+f9N+rdipbZK9PRnTbhB2Ol/jhoItEVBWxj8uz7cloaq8w8fp+tEu0v8w4MbWAKCR1l5k+jKSIyvDBd6W/Wxhg83iGgocQOK/zxzeyyQVAaUwCCj27UlANhMf0b6Y4qVGGkW5/XeAE0T4SYKuX2p7jcHra3Qrg0TNILUXvh3edTUNeLfhVI1nOi29bW8ph8YCXGxZmoW797GVNzqfHfesfsVt5XPu+v4L+euHzjPXU6fi5NmcTG+eRo4fGHkWODQbzsAgNAh3IRI4b7D8t6nBZWFkb4AUVFgpbdH/Qoz3UItM+9YoWbguscKOf2DiN9jt2jMv0DMHT1yvHW9pJ/j/l0iVVsXqrVOVAkDbotFYnxFMDBhIi7GF0Z889yA4QsqjDIBgGhBuAmRvO8OycOvb5CmSgNA1S4P/64R08rgF0LMsn5dKIEBpLKOo2po0ZBBwAAAhBPhJkTatkyQoWekVRRh+RU8uoVfptjqWDGlWwhWsUysrwDMt86xyb+Q03+eKQwzRWLHij2PFZH51jn2uPI1Y32vGWy72rpB1wgAwBaEmxDpntpSnr850+vdAAAg6nH5BQAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVTwPN7m5uZKRkSFJSUmSnZ0tK1eurHHZI0eOyJQpU6RHjx5m+b59+8rixYsjur8AAKBx8zTcLFiwQMaPHy+TJ0+WNWvWmLAydOhQKSwsDLr8ww8/LM8//7zMnDlTPvvsM7njjjvk6quvln/9618R33cAANA4xTiO49mVFLWlZsCAAfLss8+ax+Xl5dK1a1e56667ZMKECdWW79Spk0yaNEnGjh3rm/eTn/xEmjdvLvPmzavTaxYXF0tKSooUFRVJcnJyCN8NAAAIl/p8fnvWclNaWiqrV6+WIUOGVO5MbKx5vHz58qDrlJSUmO4ofxpsli5dWuPr6Dp6QPwnAABgL8/CzZ49e6SsrEzS0tIC5uvj/Pz8oOtol9X06dNl06ZNppXn/fffl0WLFsmuXbtqfJ1p06aZpOdO2jIEAADs5XlBcX0888wz0qtXL+ndu7ckJCTIuHHjZPTo0abFpyYTJ040TVjulJeXF9F9BgAAURJuUlNTJS4uTgoKCgLm6+P09PSg67Rv315ef/11OXDggGzbtk2++OILadWqlZxyyik1vk5iYqLpm/OfAACAvTwLN9ry0r9/f1myZIlvnnY16eOBAwfWuq7W3XTu3FmOHj0qr732mlx11VUR2GMAANAUxHv54joMfNSoUZKZmSlZWVkyY8YM0yqjXU1q5MiRJsRo3YxasWKF7NixQ/r162duH330UROIHnjgAS/fBgAAaEQ8DTcjRoyQ3bt3S05Ojiki1tCiJ+Vzi4y3b98eUE9z+PBhc66bLVu2mO6oyy+/XObOnStt2rTx8F0AAIDGxNPz3HiB89wAAND0NInz3AAAAIQD4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACs4nm4yc3NlYyMDElKSpLs7GxZuXJlrcvPmDFDTjvtNGnevLl07dpV7r33Xjl8+HDE9hcAADRunoabBQsWyPjx42Xy5MmyZs0a6du3rwwdOlQKCwuDLv/qq6/KhAkTzPKff/65zJ4922zjoYceivi+AwCAxsnTcDN9+nQZM2aMjB49Wvr06SOzZs2SFi1ayJw5c4Iuv2zZMjnvvPPkhhtuMK09P/7xj+X6668/bmsPAACIHp6Fm9LSUlm9erUMGTKkcmdiY83j5cuXB11n0KBBZh03zGzZskXeeecdufzyy2t8nZKSEikuLg6YAACAveK9euE9e/ZIWVmZpKWlBczXx1988UXQdbTFRtc7//zzxXEcOXr0qNxxxx21dktNmzZNHnvssZDvPwAAaJw8Lyiujw8//FCeeOIJ+d3vfmdqdBYtWiRvv/22PP744zWuM3HiRCkqKvJNeXl5Ed1nAAAQWZ613KSmpkpcXJwUFBQEzNfH6enpQdd55JFH5Oabb5bbbrvNPD7rrLPkwIEDcvvtt8ukSZNMt1ZViYmJZgIAANHBs5abhIQE6d+/vyxZssQ3r7y83DweOHBg0HUOHjxYLcBoQFLaTQUAAOBZy43SYeCjRo2SzMxMycrKMuew0ZYYHT2lRo4cKZ07dzZ1M2rYsGFmhNU555xjzomzefNm05qj892QAwAAopun4WbEiBGye/duycnJkfz8fOnXr58sXrzYV2S8ffv2gJaahx9+WGJiYsztjh07pH379ibYTJ061cN3AQAAGpMYJ8r6c3QoeEpKiikuTk5O9np3AABAiD+/m9RoKQAAgOMh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVGkW4yc3NlYyMDElKSpLs7GxZuXJljcteeOGFEhMTU2264oorIrrPAACgcfI83CxYsEDGjx8vkydPljVr1kjfvn1l6NChUlhYGHT5RYsWya5du3zThg0bJC4uTq699tqI7zsAAGh8PA8306dPlzFjxsjo0aOlT58+MmvWLGnRooXMmTMn6PJt27aV9PR03/T++++b5Qk3AADA83BTWloqq1evliFDhvjmxcbGmsfLly+v0zZmz54t1113nbRs2TLo8yUlJVJcXBwwAQAAe3kabvbs2SNlZWWSlpYWMF8f5+fnH3d9rc3RbqnbbrutxmWmTZsmKSkpvqlr164h2XcAANA4ed4t1RDaanPWWWdJVlZWjctMnDhRioqKfFNeXl5E9xEAAERWvHgoNTXVFAMXFBQEzNfHWk9TmwMHDsj8+fNlypQptS6XmJhoJgAAEB08bblJSEiQ/v37y5IlS3zzysvLzeOBAwfWuu7ChQtNPc1NN90UgT0FAABNhactN0qHgY8aNUoyMzNN99KMGTNMq4yOnlIjR46Uzp07m9qZql1Sw4cPl3bt2nm05wAAoDHyPNyMGDFCdu/eLTk5OaaIuF+/frJ48WJfkfH27dvNCCp/GzdulKVLl8p7773n0V4DAIDGKsZxHEeiiA4F11FTWlycnJzs9e4AAIAQf3436dFSAAAAVRFuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVPL+2FACgaSsrK5MjR454vRuwQEJCQrXrSZ4Iwg0A4ITopQn1gsd79+71eldgidjYWOnevbsJOQ1BuAEAnBA32HTo0EFatGghMTExXu8SmrDy8nLZuXOn7Nq1S04++eQG/T4RbgAAJ9QV5Qabdu3aeb07sET79u1NwDl69Kg0a9bshLdDQTEAoN7cGhttsQFCxe2O0vDcEIQbAMAJoysKjfH36YTCzapVq2TFihXV5uu8jz/+OBT7BQAAELlwM3bsWMnLy6s2f8eOHeY5AACAJhVuPvvsMzn33HOrzT/nnHPMcwAANFa33HKL6f6oOm3evFk++ugjGTZsmHTq1MnMe/31173eXUQq3CQmJkpBQUG1+Tp8Kz6eAVgAgMbt0ksvNZ9Z/pOeX+XAgQPSt29fyc3N9XoX0QAnlER+/OMfy8SJE+WNN96QlJQUM0+HBD700ENyySWXNGR/AAAIO/2Snp6eXm3+ZZddZiZEYbh5+umn5YILLpBu3bqZrii1du1aSUtLk7lz54Z6HwEATeSMxYeONGwI74lq3iyOkVtoWLjp3LmzrF+/Xl555RVZt26dNG/eXEaPHi3XX399g066AwBoujTY9Ml515PX/mzKUGmRUPePtLfeektatWrle6ytNQsXLgzT3iHSTrhApmXLlnL77beHdm8AAIiAiy66SJ577rmAzzREYbh58803TbLVlhm9X5srr7wyFPsGAGhCtGtIW1C8eu360DDTs2fPsO0Pmki4GT58uLlIml5HRO/XRPs8G3raZABA06P//9enawgIl/j6XK0z2H0AAGyxf/9+c74b19atW82AmbZt25orVcPS89zoxdIGDx4smzZtCs8eAQDgEb2EkI4CdkcCjx8/3tzPycnxetdQD/VuP9SaGx0pBQBAU/Tyyy/X+NyFF15ohrQjCs9QfNNNN8ns2bNDvzcAAAANdEKVX0ePHpU5c+bIX/7yF+nfv3+1IXTTp09v6H4BAABELtxs2LDBd+HML7/88sReGQAAoLGEmw8++CD0ewIAAOBVzc2tt94q+/btqzZfr6aqzwEAADSpcPM///M/cujQoWrzdd7//u//hmK/AAAAwt8tVVxcbIbI6aQtN0lJSb7n9KzE77zzjjmDMQAAQJMIN23atDGn19bp1FNPrfa8zn/sscdCuX8AAADhCzdaSKytNhdffLG89tpr5nTUroSEBOnWrZt06tSpfnsAAADgVbj50Y9+5LvWhl5jQ1tqAACIprMb//znP5e9e/dKUxQTEyN//OMfa70A9i233GLe3+uvvy5RVVCsLTRLly41ZyoeNGiQ7Nixw8yfO3eumQ8AQGOlH95uiYX/5H/BTC/Dk7s/sbGx0qVLFxk9erQUFhaGZPu7du2Syy67zNz/+uuvzevohUH9PfPMM7VeosLacKNdUkOHDpXmzZvLmjVrpKSkxMwvKiqSJ554ItT7CABASF166aXmg95/6t69uzQGycnJZn+++eYbefHFF+XPf/6z3HzzzSHZdnp6uiQmJta6TEpKiqmxjbpw88tf/lJmzZplDrpeSNN13nnnmbADAEBjph/w+kHvP8XFxZnLB5111lnmskJdu3aVO++8U/bv31/jdtatWycXXXSRtG7d2oQSvSSRXlncpb0ZP/zhD01jgG7v7rvvNueEq422puj+aA2rtrLoOnq5Iz3dSnl5uUyZMsW06Oh76NevnyxevNi3bmlpqYwbN046duxoRjRrT8u0adMCtu12N7lhTq96rvP1oqFuy5bbbfXCCy+Y/dDX9XfVVVcFnNfujTfeMFcu0Nc85ZRTzOAivVST0lrdRx991JSz6D7r9vQ9Nbpws3HjRrnggguCpr2m2g8JAGggvZp26QFvphBdyVu7gv7rv/5LPv30U3NOt7/+9a/ywAMP1Lj8jTfeaILGqlWrZPXq1TJhwgTfl/6vvvrKtBD95Cc/kfXr18uCBQtM2NHwUR8ajDRcaFjQLqPf/OY38vTTT5ttai/KlVdeKZs2bTLL6r6/+eab8oc//MF8Vr/yyiuSkZERdLsrV640txqctKVo0aJF1Za59tpr5dtvvw24MsF3331nApW+d/X3v/9dRo4cKffcc4989tln8vzzz5turalTp/p6e37729+a+bqfGq40QDa6yy9ootS+yaoHTH9omtgAAFHoyEGRJzwaMfvQTpGEwIs41+att96SVq1a+R5rC8nChQtNsbBLP+O0p+KOO+6Q3/3ud0G3s337drn//vuld+/e5nGvXr18z2mLiQYAd5v6nIYPHZzz3HPPBZwrriYaBrSnJDMz07QOaah58MEH5brrrjPP/+pXvzLBY8aMGZKbm2v2p1evXnL++eeb1hhtualJ+/btzW27du3M53owJ510kjk2r776qgwePNjM+7//+z9JTU01LVZKW2k01I0aNco81hzw+OOPm1A4efJks0+6/SFDhpjgpy04WVlZ0uhabsaMGWMS2ooVK8zB27lzp0mH9913n/zsZz+r17b0h6G/QPpDzs7O9iXJmmjL0NixY02TmzZv6fl29OSBAADUlX4wayGtO2nocFsx9EO8c+fOJkxorYu2XBw8eDDodsaPHy+33Xab+eB+8sknTWuNf5eVtmBoiHInbWnRVhgddVwTrV/VZVu0aCGnnXaapKWlmc9YPZGuft5qCYg/ffz555/7upTWrl1r1tOun/fee6/Bx0oDmra+uPW1ui8arrSVy32f2lXm/z41J2hrkB43bf3RLjUNPTpfR2u5XVaNquVGE5r+cPQXQHdcu6g0aGi4ueuuu+q8HW2i018MTaUabDR56g9em9KCnelY+xIvueQS85wmR/3l27ZtW5MvfAIAKzRrUdGC4tVr14PW1PTs2TNgno4e+rd/+zfzJV27VPRcbtoj8dOf/tR8/mjYqEprSW644QZ5++23TeGvtlTMnz9frr76alOr85//+Z9B60u09aImGqq0flXDg36R124ppeHmeLTuZevWrWZfNKj9x3/8hwle+pl5ooYNG2bqZvQ9DhgwwHRDaTeTS9+ntt5cc8011dbVhgutNdLPdd2f999/39QxPfXUU/K3v/0toG7X83CjrTWTJk0yTXHaPaVvrE+fPgFNfHWhhVua4nSYm9KQowdvzpw5JkBVpfO1r2/ZsmW+A1JTX6JLk6abNuv6ywEAOAF67rN6dA01Nlozo1/ctabFbZXQ2pXj0R4Ene699165/vrr5aWXXjLhRoOG1qBUDVHHo68dbB0tWNZi3H/84x++884pfezfzZOcnCwjRoww07//+7+buh/97PQ/8a578l338km10YCiwUVbbPQzX1uF9L259L6Gl9repwY0DUk6ae+LduN98sknAdvxLNzU9YrfGkKOR1Ow/iJNnDgx4AeqCXP58uVB19EiqYEDB5oDo5XZ2l+oiVn7H7XKPRjt8+SSEACA49EP5yNHjsjMmTPNh7CGBv3SXRPtatEv+RogdOSRDt3WwmItIFb62fSDH/zAFBBr15W2FmnY0daLZ5999oT2UV9PW4d69OhhRkppkNJuKA0ebqNBx44dzQgo/UzVOiKtdwnWw6G9IBo6tDhYi6I1xOjAoJq6prRVSwut9Rx3/nJycsxz2hqlx0JfV7uqNmzYYGqWtGtOA5T20Gjr17x588zr1lYPFNGaG91BLVzSupfvv/++xqku9uzZY96s9iX608f5+flB19myZYtpWnMv0vnII4+YhK0HryYanrT/0p3y8vLq85YBAFGib9++Jhxoke6ZZ55pAoP/MOqq9Eu11uPoSCFtudEuIC2+db9Qn3322abr5csvvzTDwTVwaBBoyGWKtItLyzl+8YtfmBFHGkz0i79byKxdWr/+9a9NAbJ2IWlXm35eui1R/uLj402tkY5i0n3S4d010csuacuPttBoo4I/LSfRAm2t79HX1ECn3VZueNFgpaeO0dogPSbaPfWnP/3JFDKHS4yjHWl1pC0mv//9780Oa1eSpreqzVx1pUVRWjOjXUzaGuPS6mr9ZdBi5ar0l+fw4cOmP9FtqdFfRO2708KlutBuKU2mGnS06Q4AUH/u/8XaYlGXUT9AQ3+v6vP5HVvfkU0aIjSAaOrSIiFNqu+++64pNqoPHUamAaWgoCBgvj6uaUiaNrVpwPHvgjr99NNNS492cwEAANR7KLiOitKCKe0z1L7DM844w1Q+a2FvbWdxrEoLmfRMjkuWLPHN00IufezfkuNPm7S0mMn/TIna3Kehxy2MAgAA0S22QSvHxpqRU9pqc7xq62C031D74fQskDpGX4ff6Wmp3dFT2o/pX3Csz2vFt55jR0ONjqzSa1lpdxkAAMAJDQXXYdV6imYdEaXj/7VCWqu+dahZsIKl2ugwtd27d5sCK+1acq+R4RYZ61kN/bep3WDaBabD7bQoSWt2NOhoRToAAEC9C4q1+0lPTqQhQ4eF69AwrZ1pSigoBoDQFX5qSYJ7kjmgoXR4vY7wamhBcb1abnS8v45j11Mo64gmnYIJdvEtAIA93BOp6lnqCTcIFXdwUE3nrqureoUbrYHRGhsAQHTTDx89f0lhYaF5rCdn4/MBDaGDhbRURX+X9Bw8DRFf35P4AQCg3NN2uAEHaCits9UeooYG5YZFIwBA1NIPID0Vh57GXy9bADSUntalvoOTgiHcAAAa3EXV0BoJIJQaHo8AAAAaEcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKs0inCTm5srGRkZkpSUJNnZ2bJy5coal3355ZclJiYmYNL1AAAAGkW4WbBggYwfP14mT54sa9askb59+8rQoUOlsLCwxnWSk5Nl165dvmnbtm0R3WcAANB4eR5upk+fLmPGjJHRo0dLnz59ZNasWdKiRQuZM2dOjetoa016erpvSktLq3HZkpISKS4uDpgAAIC9PA03paWlsnr1ahkyZEjlDsXGmsfLly+vcb39+/dLt27dpGvXrnLVVVfJp59+WuOy06ZNk5SUFN+k6wAAAHt5Gm727NkjZWVl1Vpe9HF+fn7QdU477TTTqvPGG2/IvHnzpLy8XAYNGiTffPNN0OUnTpwoRUVFvikvLy8s7wUAADQO8dLEDBw40EwuDTann366PP/88/L4449XWz4xMdFMAAAgOnjacpOamipxcXFSUFAQMF8fay1NXTRr1kzOOecc2bx5c5j2EgAANCWehpuEhATp37+/LFmyxDdPu5n0sX/rTG20W+uTTz6Rjh07hnFPAQBAU+F5t5QOAx81apRkZmZKVlaWzJgxQw4cOGBGT6mRI0dK586dTWGwmjJlivzgBz+Qnj17yt69e+Wpp54yQ8Fvu+02j98JAABoDDwPNyNGjJDdu3dLTk6OKSLu16+fLF682FdkvH37djOCyvX999+boeO67EknnWRafpYtW2aGkQMAAMQ4juNIFNHz3OiQcB05pScDBAAAdn1+e34SPwAAgFAi3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVGkW4yc3NlYyMDElKSpLs7GxZuXJlndabP3++xMTEyPDhw8O+jwAAoGnwPNwsWLBAxo8fL5MnT5Y1a9ZI3759ZejQoVJYWFjrel9//bXcd9998sMf/jBi+woAABo/z8PN9OnTZcyYMTJ69Gjp06ePzJo1S1q0aCFz5sypcZ2ysjK58cYb5bHHHpNTTjklovsLAAAaN0/DTWlpqaxevVqGDBlSuUOxsebx8uXLa1xvypQp0qFDB/npT3963NcoKSmR4uLigAkAANjL03CzZ88e0wqTlpYWMF8f5+fnB11n6dKlMnv2bHnxxRfr9BrTpk2TlJQU39S1a9eQ7DsAAGicPO+Wqo99+/bJzTffbIJNampqndaZOHGiFBUV+aa8vLyw7ycAAPBOvIevbQJKXFycFBQUBMzXx+np6dWW/+qrr0wh8bBhw3zzysvLzW18fLxs3LhRevToEbBOYmKimQAAQHTwtOUmISFB+vfvL0uWLAkIK/p44MCB1Zbv3bu3fPLJJ7J27VrfdOWVV8pFF11k7tPlBAAAPG25UToMfNSoUZKZmSlZWVkyY8YMOXDggBk9pUaOHCmdO3c2tTN6HpwzzzwzYP02bdqY26rzAQBAdPI83IwYMUJ2794tOTk5poi4X79+snjxYl+R8fbt280IKgAAgLqIcRzHkSiiQ8F11JQWFycnJ3u9OwAAIMSf3zSJAAAAq3jeLQUAAHRETZlI8Q6R77aKfP+1yPdbRfbmiZQfkSanXU+RwTmevTzhBgCASCk9UBFc/AOMe3/v9qYZZILpkiVeItwAABAqWsa6vzAwtOh9N9AcqP2i0BLbTOSkbiIndRc5KaPifnySNDmtAq88EGmEGwAA6uNoSUV3kX9oce/rdORg7esntRFp270ywLR1g0x3keROIrFxkXon1iLcAABQ1cHvqre6uOGl6Bttoql53ZhYkeQuIm0zggSYDJHmJ0XynUQlwg0AIMqLd6sGmK0ih4tqX79Zy+qhxW2NSekqEp8QqXeCIAg3AAD7W2G2fCiyfbnIt1/VvXhX60Y0rPh3G7khpmV7kZiYSL0D1BPhBgBgX03M9n+KbPlA5KsPRHatC96NVLV4178ORucntPRi7xEChBsAQNMfoVT4WUWQ0UCzbVn1ot72p4uccqFIWh+Kd6MA4QYA0PTsy6/oanIDzf6CwOdbdhDpcZHIKTpdKJLc0as9hQcINwCApnHyO22RccOMttT4i28u0m1QZaBJO4OamChGuAEAND7l5SK71lbWzeStECkr9VsgRqTj2SI9Lq4IM12zRZo1wZPdISwINwCAxkFHMLktM9rldOj7wOd1iLV2MWnrTPcLRVq282pP0cgRbgAA3tBzyWz9e2XrzHdfBT6f0Fqk+w8rW2fa9aCrCXVCuAEAREbZEZEdqytbZ775WMQpq3w+Jk6kS2ZFkNHWmc79ReKaebnHaKIINwCA8A3R1pPmuS0zWz8SKd0XuEzbHpVFwNpKk5Ti1d7CIoQbAEDozwb81V8rbovyAp/X6ypp3YzbOtPmZK/2FBYj3AAAwnc24LiEipFMbutMx76cOA9hR7gBANS9ZkZHNOmFJQs/r2iZCXY24A59KouAuw3kMgaIOMINAKDSob2VV8aueqXsom9EnPLgF5h0u5m0y6l1uhd7DvgQbgAg2k6Ot2/nsdASJMBUPbdMVXomYHORyVOOnRH4YpEOpzNEG40K4QYAbFN6UGTvtuABRucHnOk3CL0uk+8q2ccuMune11YaggwaOcINADTFIdYHdldvdXHv78+vff3YZhWjlIIFmDbdRBJbReqdAGFBuAGAxuhoacUwav/Q4h9mjhyofX09X4wGlmABJrkzI5ZgNcINAHhavBuk7uW7r0WKayje9YkRSelyLLQECTB6PhkgShFuACBcystEincGDzB6e7zi3WYtKgNL1QDTpqtIfGKk3gnQpBBuAKChxbtul1FAF9LWinPC1KV414SWIAGmVQeKd4ETQLgBgLoU7wYr3NX7+wvqVrwbbOSRTpzgDgg5wg0AuMW7/kOnT6R41z/AuK0wFO8CEUe4ARBdxbtV615OuHjXL8BQvAs0KoQbANWVHa1oydArPDc1pfsDa2DcFpjDe2tfj+JdwBqEGyBaleyruY5kb56IUybW8RXvVq19oXgXsAnhBrD5GkJ6ptpq3TDH6koOflv7+nGJTfMDX/f7pG7BW2Eo3gWiAuEGaMqOHPa7hlCVAKPzjx6uff0W7Wo+i22rdJHY2Ei9EwAIGcIN0NiHIWvdS9BC2K0VV3euTUxcRb1IsACjt0nJkXonABAxhBugsRTvVu02ckfylO6rff2E1iJtM4LXkegIn7hmkXonANAoEG5C5WjJ8U/mhehW7TpCx+7XpXi3daeaC2FbtG16dTEAEEaEm1DZtV5k9hCv9wJNlSmCDdJtpI/bdBNpluT1HgJAk0G4CRX95hzPBxBqoSN1ajqLLcW7ABAyhJtQ6ZIp8jDdUgAAeI2vigAAwCqEGwAAYJVGEW5yc3MlIyNDkpKSJDs7W1auXFnjsosWLZLMzExp06aNtGzZUvr16ydz586N6P4CAIDGy/Nws2DBAhk/frxMnjxZ1qxZI3379pWhQ4dKYWFh0OXbtm0rkyZNkuXLl8v69etl9OjRZnr33Xcjvu8AAKDxiXEcPQWqd7SlZsCAAfLss8+ax+Xl5dK1a1e56667ZMKECXXaxrnnnitXXHGFPP7448ddtri4WFJSUqSoqEiSkzk7KwAATUF9Pr89bbkpLS2V1atXy5AhleeHiY2NNY+1ZeZ4NJctWbJENm7cKBdccEHQZUpKSswB8Z8AAIC9PA03e/bskbKyMklLSwuYr4/z8/NrXE9TW6tWrSQhIcG02MycOVMuueSSoMtOmzbNJD130lYhAABgL89rbk5E69atZe3atbJq1SqZOnWqqdn58MMPgy47ceJEE4bcKS8vL+L7CwAAouQkfqmpqRIXFycFBYEnv9PH6enpNa6nXVc9e/Y093W01Oeff25aaC688MJqyyYmJpoJAABEB09bbrRbqX///qZuxqUFxfp44MCBdd6OrqO1NQAAAJ5ffkG7lEaNGmXOXZOVlSUzZsyQAwcOmOHdauTIkdK5c2fTMqP0Vpft0aOHCTTvvPOOOc/Nc8895/E7AQAAjYHn4WbEiBGye/duycnJMUXE2s20ePFiX5Hx9u3bTTeUS4PPnXfeKd988400b95cevfuLfPmzTPbAQAA8Pw8N5HGeW4AAGh6msx5bgAAAKzrloo0t6GKk/kBANB0uJ/bdelwirpws2/fPnPLyfwAAGian+PaPVWbqKu50WHjO3fuNCcCjImJCXmq1NCkJwqknid8OM6RwXGODI5z5HCsm/Zx1riiwaZTp04BA42CibqWGz0gXbp0Cetr6A+TP5zw4zhHBsc5MjjOkcOxbrrH+XgtNi4KigEAgFUINwAAwCqEmxDSa1hNnjyZa1mFGcc5MjjOkcFxjhyOdfQc56grKAYAAHaj5QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbmqRm5srGRkZkpSUJNnZ2bJy5cpal9+7d6+MHTtWOnbsaKrETz31VHnnnXcatM1oEepjPW3aNBkwYIA5E3WHDh1k+PDhsnHjRol24fiddj355JPmrN8///nPJdqF4zjv2LFDbrrpJmnXrp00b95czjrrLPn4448lmoX6OJeVlckjjzwi3bt3N8e4R48e8vjjj9fpWkY2y63Hcb7wwgvN/wNVpyuuuMK3jB7PnJwc83PQ4zxkyBDZtGlTaHdaR0uhuvnz5zsJCQnOnDlznE8//dQZM2aM06ZNG6egoCDo8iUlJU5mZqZz+eWXO0uXLnW2bt3qfPjhh87atWtPeJvRIhzHeujQoc5LL73kbNiwwczXZU8++WRn//79TrQKx3F2rVy50snIyHDOPvts55577nGiWTiO83fffed069bNueWWW5wVK1Y4W7Zscd59911n8+bNTrQKx3GeOnWq065dO+ett94yzy9cuNBp1aqV88wzzzjRan49j/O3337r7Nq1yzfp/8FxcXHm/2PXk08+6aSkpDivv/66s27dOufKK690unfv7hw6dChk+024qUFWVpYzduxY3+OysjKnU6dOzrRp04Iu/9xzzzmnnHKKU1paGrJtRotwHOuqCgsL9auX87e//c2JVuE6zvv27XN69erlvP/++86PfvSjqA834TjODz74oHP++eeHZX+bqnAc5yuuuMK59dZbA+Zdc801zo033uhEq6wGfm799re/dVq3bu37YlleXu6kp6c7Tz31lG+ZvXv3OomJic7vf//7kO033VJBlJaWyurVq01Tmf81qfTx8uXLg67z5ptvysCBA02TZ1pampx55pnyxBNPmGbOE91mNAjHsQ6mqKjI3LZt21aiUTiPsz6vTc7+245W4TrOukxmZqZce+21ppv1nHPOkRdffFGiVbiO86BBg2TJkiXy5Zdfmsfr1q2TpUuXymWXXSbRqDQEn1uzZ8+W6667Tlq2bGkeb926VfLz8wO2qdeL0u6uUH4WRt2FM+tiz5495hde/wD86eMvvvgi6DpbtmyRv/71r3LjjTeaPtzNmzfLnXfeKUeOHDFnajyRbUaDcBzrYFeC1zqQ8847z/yHFo3CdZznz58va9askVWrVkXkfUTrcdZlnnvuORk/frw89NBD5njffffdkpCQIKNGjZJoE67jPGHCBHNF6969e0tcXJx5jalTp5p1otGeBn5uaW3Ohg0bTMBxabBxt1F1m+5zoUC4CRH9ANVvVC+88IL5o+jfv78pAHzqqaeCfuAicsdav6npH5h+A0PojnNeXp7cc8898v7775tCQ4Tv91mX0ZYbbWlQ2nKjv9OzZs2KynATruP8hz/8QV555RV59dVX5YwzzpC1a9eaL0adOnXiOJ8ADTVa+J6VlSWRRrgJIjU11fzyFxQUBMzXx+np6UHX0arvZs2amfVcp59+ukmi2rR3ItuMBuE41vpt1jVu3Dh566235KOPPpIuXbpItArHcdbm6sLCQjn33HN9z+u3PD3Wzz77rJSUlASsGw3C9fusy/Tp0ydgPV3mtddek2gUruN8//33m9Yb7UZR+sG8bds2M/oyGsNNagM+tw4cOGBadqdMmRIw311Pt6E/E/9t9uvXL2T7Ts1NEPpLrqle+179U78+1j7bYLTLQ5s5dTmX9tvqD0+3dyLbjAbhONZKi+U12Pzxj380TdE6tDOaheM4Dx48WD755BPz7dadtHVBm/D1frQFm3D+PusyVU9loMt069ZNolG4jvPBgwdNTYk//T32XyeaJDTgc2vhwoXmC46evsCf/l+sAcd/m9oVuGLFitB+FoasNNnC4W9avf3yyy87n332mXP77beb4W/5+fnm+ZtvvtmZMGGCb/nt27ebivBx48Y5GzduNEMJO3To4Pzyl7+s8zajVTiO9c9+9jMz1FCHevoPSzx48KATrcJxnKtitFR4jrMOtY+PjzdDlTdt2uS88sorTosWLZx58+Y50Socx3nUqFFO586dfUPBFy1a5KSmpjoPPPCAE63m1/M4u3R034gRI4JuU4eC6zbeeOMNZ/369c5VV13FUPBImjlzpjk3io7x1+Fw//znPwP+E9c/BH/Lli1zsrOzzS+CDjnU/4iOHj1a521Gs1Afa83twSb/cy1Eo3D8Tvsj3ITvOP/pT39yzjzzTLNM7969nRdeeMGJdqE+zsXFxeb3V7eZlJRklpk0aZI5R040m1nP4/zFF1+Y/2/fe++9oNvT4eCPPPKIk5aWZn4WgwcPNoEzlGL0n9C1AwEAAHiLmhsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAR8+GHH0pMTIzs3bs3oq/78ssvS5s2bRq0ja+//trsu143q7G9PwCBCDcAQkI/1GubHn30Ua93EUCUiPd6BwDYYdeuXb77CxYskJycnIArWbdq1Uo+/vjjem+3tLTUd9VmAKgLWm4AhER6erpvSklJMa01/vM03LhWr14tmZmZ0qJFCxk0aFBACNIWnn79+sl///d/S/fu3SUpKcnM166e2267Tdq3by/Jycly8cUXy7p163zr6f2LLrpIWrdubZ7v379/tTD17rvvyumnn2725dJLLw0IZOXl5TJlyhTp0qWLJCYmmn1YvHhxre/5nXfekVNPPVWaN29uXlu7rgB4j3ADIOImTZokv/nNb0z4iI+Pl1tvvTXg+c2bN8trr70mixYt8tW4XHvttVJYWCh//vOfTTg699xzZfDgwfLdd9+Z52+88UYTTFatWmWenzBhgjRr1sy3zYMHD8rTTz8tc+fOlY8++ki2b98u9913n+/5Z555xuyTLrN+/XoZOnSoXHnllbJp06ag7yEvL0+uueYaGTZsmNlHDV76mgAagZBeYxwAHMd56aWXnJSUlGrzP/jgA0f/2/nLX/7im/f222+beYcOHTKPJ0+e7DRr1swpLCz0LfP3v//dSU5Odg4fPhywvR49ejjPP/+8ud+6dWvn5ZdfrnF/9DU2b97sm5ebm+ukpaX5Hnfq1MmZOnVqwHoDBgxw7rzzTnN/69atZhv/+te/zOOJEyc6ffr0CVj+wQcfNMt8//33dTpOAMKDlhsAEXf22Wf77nfs2NHcaquMq1u3bqb7yb/Laf/+/dKuXTvTpeROW7dula+++sosM378eNN6MmTIEHnyySd9813aBdajR4+A13Vfs7i4WHbu3CnnnXdewDr6+PPPPw/6HnR+dnZ2wLyBAwee0PEAEFoUFAOIOP/uIq3NcWteXC1btgxYXoONhhEdal2VO8Rba3VuuOEGefvtt03X1eTJk2X+/Ply9dVXV3tN93UdRxtaANiGlhsAjZ7W1+Tn55v6nJ49ewZMqampvuW0uPfee++V9957z9TDvPTSS3XavhYgd+rUSf7xj38EzNfHffr0CbqOFiavXLkyYN4///nPE3p/AEKLcAOg0dOuJu3yGT58uAkuOipp2bJlpjBZi5IPHTok48aNMy0727ZtM6FEC4s1gNTV/fffL7/61a/MMHYdvaXFwVoofM899wRd/o477jDFxrqeLv/qq6+akwUC8B7dUgAaPe1C0mHXGmZGjx4tu3fvNsPLL7jgAklLS5O4uDj59ttvZeTIkVJQUGBac7Tl5rHHHqvza9x9991SVFQkv/jFL0wtjrbYvPnmm9KrV6+gy5988slmRJe2FM2cOVOysrLkiSeeqDbyC0DkxWhVsQevCwAAEBZ0SwEAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AABAbPL/t66V1JKlG90AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mental-RoBERTa + Relabeled + Personality + NLI Evaluation with Dual Optimization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# ===== Load both datasets =====\n",
    "# Performance test dataset\n",
    "df_performance = pd.read_csv('../dataset/testing_1000_samples_2.csv')\n",
    "true_labels_perf = df_performance['true_class'].map({'non-suicide':0, 'suicide':1}).values\n",
    "\n",
    "# False positive test dataset\n",
    "df_fp = pd.read_csv('../dataset/false_positive_test_set_with_personality.csv')  \n",
    "true_labels_fp = [0] * len(df_fp)  # All should be non-suicide\n",
    "\n",
    "print(f\"Performance dataset size: {len(df_performance)}\")\n",
    "print(f\"FP test dataset size: {len(df_fp)}\")\n",
    "\n",
    "# ===== Device =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Load personality features for both datasets =====\n",
    "personality_features_perf = df_performance[[\"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "personality_features_perf = torch.tensor(personality_features_perf, dtype=torch.float32).to(device)\n",
    "\n",
    "personality_features_fp = df_fp[[\"extraversion\", \"agreeableness\", \"neuroticism\"]].values\n",
    "personality_features_fp = torch.tensor(personality_features_fp, dtype=torch.float32).to(device)\n",
    "\n",
    "model_dir = \"../saved_models/mental_roberta_personality\"\n",
    "# ===== Tokenizer =====\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "class RoBertaWithPersonality(RobertaPreTrainedModel):\n",
    "    def __init__(self, config, personality_feat_dim=3, num_labels=2):\n",
    "        super().__init__(config)\n",
    "        self.bert = AutoModel.from_pretrained(model_dir, config=config)\n",
    "        bert_hidden_size = config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert_hidden_size + personality_feat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, personality_feats, labels=None):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = bert_outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "        combined = torch.cat((cls_output, personality_feats), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# ===== Load pretrained BERT + Personality model =====\n",
    "config = AutoConfig.from_pretrained(model_dir, num_labels=2)\n",
    "bert_personality_model = RoBertaWithPersonality.from_pretrained(model_dir, config=config)\n",
    "bert_personality_model.to(device).eval()\n",
    "\n",
    "# ===== Load pretrained NLI model =====\n",
    "nli_model_name = \"tasksource/deberta-small-long-nli\"\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name).to(device).eval()\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
    "\n",
    "# ===== Negative hypotheses for NLI filtering =====\n",
    "negative_hypotheses = [\n",
    "    \"The author discusses suicide in general, awareness, or prevention, not personal suicidal thoughts.\",\n",
    "    \"The post shares support, resources, or hotlines, not the author's own suicidal intent.\",\n",
    "    \"The author reflects to inspire or thank others, not describing current suicidal thoughts.\"\n",
    "]\n",
    "\n",
    "# ===== Helper: NLI negative filtering =====\n",
    "def nli_negative_filter(post, threshold=0.65):\n",
    "    max_neg_entail_prob = 0\n",
    "    for hypo in negative_hypotheses:\n",
    "        inputs = nli_tokenizer(post, hypo, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = nli_model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=-1)[0]  # [entail, neutral, contradict]\n",
    "            entail_prob = probs[0].item()  # entailment probability\n",
    "        max_neg_entail_prob = max(max_neg_entail_prob, entail_prob)\n",
    "    return max_neg_entail_prob >= threshold\n",
    "\n",
    "# ===== Function to evaluate dataset with specific threshold =====\n",
    "def evaluate_dataset(df, personality_features, true_labels, threshold, dataset_name=\"Dataset\"):\n",
    "    final_predictions = []\n",
    "    batch_size = 16\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_texts = df['cleaned_text'][i:i+batch_size].tolist()\n",
    "        batch_personality = personality_features[i:i+batch_size]\n",
    "\n",
    "        # BERT tokenization\n",
    "        encodings = bert_tokenizer(\n",
    "            batch_texts,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encodings['input_ids'].to(device)\n",
    "        attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "        # BERT + Personality predictions\n",
    "        with torch.no_grad():\n",
    "            logits = bert_personality_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                personality_feats=batch_personality\n",
    "            )\n",
    "            batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        # Apply NLI negative filtering with current threshold\n",
    "        for text, pred in zip(batch_texts, batch_preds):\n",
    "            if pred == 1:  # initially predicted as suicide\n",
    "                is_negative = nli_negative_filter(text, threshold=threshold)\n",
    "                final_predictions.append(0 if is_negative else 1)\n",
    "            else:\n",
    "                final_predictions.append(pred)\n",
    "\n",
    "        # Free GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(true_labels, final_predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    precision = precision_score(true_labels, final_predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, final_predictions, zero_division=0)\n",
    "    f1 = f1_score(true_labels, final_predictions, zero_division=0)\n",
    "    accuracy = np.mean(np.array(final_predictions) == true_labels)\n",
    "    \n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'dataset': dataset_name,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'fpr': fpr,\n",
    "        'fp': fp,\n",
    "        'tp': tp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'predictions': final_predictions\n",
    "    }\n",
    "\n",
    "# ===== Multi-objective threshold optimization =====\n",
    "thresholds_to_test = [0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70]\n",
    "results = []\n",
    "\n",
    "print(\"Testing thresholds for dual optimization (performance + FP reduction)...\")\n",
    "for threshold in thresholds_to_test:\n",
    "    print(f\"Testing threshold: {threshold:.2f}\")\n",
    "    \n",
    "    # Evaluate on performance dataset\n",
    "    result_perf = evaluate_dataset(df_performance, personality_features_perf, true_labels_perf, threshold, \"Performance\")\n",
    "    \n",
    "    # Evaluate on FP dataset\n",
    "    result_fp = evaluate_dataset(df_fp, personality_features_fp, true_labels_fp, threshold, \"FP_Test\")\n",
    "    \n",
    "    results.append(result_perf)\n",
    "    results.append(result_fp)\n",
    "    \n",
    "    print(f\"  Performance - F1: {result_perf['f1_score']:.4f}, FP: {result_perf['fp']}\")\n",
    "    print(f\"  FP Test - FPR: {result_fp['fpr']:.4f}, FP: {result_fp['fp']}\")\n",
    "\n",
    "# ===== Find optimal threshold using multi-objective optimization =====\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Separate results by dataset\n",
    "perf_results = results_df[results_df['dataset'] == 'Performance']\n",
    "fp_results = results_df[results_df['dataset'] == 'FP_Test']\n",
    "\n",
    "# Create combined scoring metric\n",
    "combined_scores = []\n",
    "for threshold in thresholds_to_test:\n",
    "    perf_data = perf_results[perf_results['threshold'] == threshold].iloc[0]\n",
    "    fp_data = fp_results[fp_results['threshold'] == threshold].iloc[0]\n",
    "    \n",
    "    # Weighted combination of F1 (performance) and 1-FPR (FP reduction)\n",
    "    # Adjust weights based on your priorities (0.7:0.3 favors performance, 0.5:0.5 balanced)\n",
    "    weight_performance = 0.8\n",
    "    weight_fp = 0.2\n",
    "    \n",
    "    # Normalize F1 score (0-1)\n",
    "    normalized_f1 = perf_data['f1_score']\n",
    "    \n",
    "    # Normalize FP reduction (1-FPR, higher is better)\n",
    "    normalized_fp_reduction = 1 - fp_data['fpr']\n",
    "    \n",
    "    # Combined score\n",
    "    combined_score = (weight_performance * normalized_f1) + (weight_fp * normalized_fp_reduction)\n",
    "    \n",
    "    combined_scores.append({\n",
    "        'threshold': threshold,\n",
    "        'combined_score': combined_score,\n",
    "        'f1_score': perf_data['f1_score'],\n",
    "        'fpr': fp_data['fpr'],\n",
    "        'fp_count': fp_data['fp'],\n",
    "        'performance_fp': perf_data['fp']\n",
    "    })\n",
    "\n",
    "combined_df = pd.DataFrame(combined_scores)\n",
    "\n",
    "df_valid = combined_df[combined_df['f1_score'] >= 0.93]\n",
    "\n",
    "# Select threshold with the highest combined score\n",
    "best_idx = df_valid['combined_score'].idxmax()\n",
    "best_threshold = df_valid.loc[best_idx, 'threshold']\n",
    "best_combined_score = combined_df.loc[best_idx, 'combined_score']\n",
    "best_f1 = df_valid.loc[best_idx, 'f1_score']\n",
    "best_fp = df_valid.loc[best_idx, 'fp_count']\n",
    "\n",
    "print(f\"Selected threshold: {best_threshold}\")\n",
    "print(f\"F1 Score: {best_f1}\")\n",
    "print(f\"False Positives: {best_fp}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTI-OBJECTIVE THRESHOLD OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(combined_df.round(4))\n",
    "print(f\"\\nBest threshold: {best_threshold:.2f}\")\n",
    "print(f\"Combined score: {best_combined_score:.4f}\")\n",
    "print(f\"Performance F1: {combined_df.loc[best_idx, 'f1_score']:.4f}\")\n",
    "print(f\"FP Test FPR: {combined_df.loc[best_idx, 'fpr']:.4f}\")\n",
    "print(f\"FP Count: {combined_df.loc[best_idx, 'fp_count']}\")\n",
    "\n",
    "# ===== Final evaluation with optimal threshold =====\n",
    "print(f\"\\nFinal evaluation with optimal threshold: {best_threshold:.2f}\")\n",
    "\n",
    "# Performance dataset\n",
    "final_perf = evaluate_dataset(df_performance, personality_features_perf, true_labels_perf, best_threshold, \"Performance_Final\")\n",
    "print(\"\\nPerformance Dataset Results:\")\n",
    "print(f\"F1 Score: {final_perf['f1_score']:.4f}\")\n",
    "print(f\"Precision: {final_perf['precision']:.4f}\")\n",
    "print(f\"Recall: {final_perf['recall']:.4f}\")\n",
    "print(f\"False Positives: {final_perf['fp']}\")\n",
    "\n",
    "# FP dataset\n",
    "final_fp = evaluate_dataset(df_fp, personality_features_fp, true_labels_fp, best_threshold, \"FP_Test_Final\")\n",
    "print(\"\\nFP Test Dataset Results:\")\n",
    "print(f\"False Positive Rate: {final_fp['fpr']:.4f}\")\n",
    "print(f\"False Positives: {final_fp['fp']}\")\n",
    "print(f\"True Negatives: {final_fp['tn']}\")\n",
    "\n",
    "# ===== Comparison with baseline (no NLI) =====\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"COMPARISON WITH BASELINE (NO NLI FILTERING)\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Baseline for performance dataset\n",
    "baseline_perf = evaluate_dataset(df_performance, personality_features_perf, true_labels_perf, 0.0, \"Baseline\")\n",
    "print(f\"Performance Baseline F1: {baseline_perf['f1_score']:.4f} → With NLI: {final_perf['f1_score']:.4f}\")\n",
    "print(f\"Performance Baseline FP: {baseline_perf['fp']} → With NLI: {final_perf['fp']}\")\n",
    "\n",
    "# Baseline for FP dataset (all should be 0 predictions)\n",
    "baseline_fp_predictions = []\n",
    "for i in range(0, len(df_fp), 16):\n",
    "    batch_personality = personality_features_fp[i:i+16]\n",
    "    batch_texts = df_fp['cleaned_text'][i:i+16].tolist()\n",
    "    \n",
    "    encodings = bert_tokenizer(\n",
    "        batch_texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = bert_personality_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            personality_feats=batch_personality\n",
    "        )\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        baseline_fp_predictions.extend(batch_preds.tolist())\n",
    "\n",
    "baseline_fp_count = sum(baseline_fp_predictions)\n",
    "print(f\"FP Test Baseline FP: {baseline_fp_count} → With NLI: {final_fp['fp']}\")\n",
    "print(f\"FP Reduction: {((baseline_fp_count - final_fp['fp']) / baseline_fp_count * 100):.1f}%\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(thresholds_to_test, perf_results['f1_score'], label='F1')\n",
    "plt.plot(thresholds_to_test, fp_results['fpr'], label='False Positives')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
